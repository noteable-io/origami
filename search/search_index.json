{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Origami","text":""},{"location":"#intro-to-origami","title":"Intro to Origami","text":"<p>Origami is a \ud83d\udc0d Python library for talking to Noteable notebooks. This is the official way to access the full breadth of API calls and access patterns in async Python for rich programmatic access to notebooks. You can use Noteable for free with a quick signup.</p>"},{"location":"#requirements","title":"Requirements","text":"<p>Python 3.8+</p>"},{"location":"#installation","title":"Installation","text":"<p>For stable release:</p> <pre><code>pip install noteable-origami\n</code></pre> <pre><code>poetry add noteable-origami\n</code></pre> <p>For alpha pre-release:</p> <pre><code>pip install noteable-origami --pre\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>See Contributing page.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p> <p>For pre-1.0 releases, see 0.0.35 Changelog</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#200-2023-11-06","title":"[2.0.0] - 2023-11-06","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Upgraded pydantic to 2.4.2 up from 1.X.</li> </ul>"},{"location":"changelog/#115-2023-11-06","title":"[1.1.5] - 2023-11-06","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Try to reduce error spam when file subscribe replies return inconsistent state events</li> </ul>"},{"location":"changelog/#114-2023-10-23","title":"[1.1.4] - 2023-10-23","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Programmatically adjust Space, Project, and Notebook/File visibility (e.g. <code>private</code>, <code>open</code>, <code>public</code>)</li> </ul>"},{"location":"changelog/#113-2023-10-23","title":"[1.1.3] - 2023-10-23","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Programmatically share access to Spaces, Projects, and Notebooks/Files by email and access level. E.g. <code>await api_client.share_file(file_id, email, 'viewer')</code></li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Removed <code>RuntimeError</code> in RTUClient catastrophic failure, top level applications (e.g. PA, Origamist) should define that behavior</li> </ul>"},{"location":"changelog/#112-2023-10-12","title":"[1.1.2] - 2023-10-12","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Environ variable <code>NOTEABLE_RTU_URL</code> to override RTU websocket, primarily for when apps are running in-cluster with Gate and need to use the http vs websocket service DNS</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Move the code logic for discovering recent version id and downloading seed Notebook from <code>APIClient</code> to <code>RTUClient</code></li> </ul>"},{"location":"changelog/#111-2023-10-04","title":"[1.1.1] - 2023-10-04","text":""},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li><code>rtu_client_type</code> renamed to <code>client_creator_type</code>, now used both in RTU auth subscribe and when creating Files/Projects</li> <li><code>RTUClient</code> crashes if trying to instantiate with no file version id, which can happen after a Notebook has been changed from non-RTU mechanism</li> </ul>"},{"location":"changelog/#110-2023-09-28","title":"[1.1.0] - 2023-09-28","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>CLI for downloading Notebooks and tailing a Notebook to see all RTU messages</li> <li>Modeling for RTU messages that were missing</li> <li><code>variable_explorer_request</code> on Kernels channel</li> <li><code>append_output_event</code> on Files channel</li> <li><code>v0_create_widget_model_event</code> on Files channel</li> <li>Configuration options for <code>APIClient</code> and e2e tests from env variables. Use <code>NOTEABLE_TOKEN</code> and <code>NOTEABLE_API_URL</code> with <code>APIClient</code></li> <li><code>APIClient.get_file_versions</code> to list all versions of a file, including version id, version number, and presigned url to download content for that version</li> <li>Updated docs for Origami 1.x syntax</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>Raise a Runtime Error if trying to send a cell execute request when no Kernel is running</li> <li>This is technically handled fine within Noteable and the execute is queued until Kernel starts, but is an easy foot-gun for end users</li> </ul>"},{"location":"changelog/#100-2023-09-08","title":"[1.0.0] - 2023-09-08","text":""},{"location":"changelog/#100-alpha5-2023-08-16","title":"[1.0.0-alpha.5] - 2023-08-16","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Optional output-for-LLM field in KernelOutput model</li> <li><code>integrated_ai*</code> message models for the <code>kernels</code> channel</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Create <code>RTUClient.kernel_pod_name</code> with the right suffix</li> </ul>"},{"location":"changelog/#100-alpha4-2023-08-08","title":"[1.0.0-alpha.4] - 2023-08-08","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li><code>rtu_client.update_cell_content</code> that takes cell id and a diff-match-patch patch str</li> </ul>"},{"location":"changelog/#changed_5","title":"Changed","text":"<ul> <li>Temporary guard against invalid <code>rtu_client_type</code> names when initiating <code>APIClient</code></li> </ul>"},{"location":"changelog/#100-alpha3-2023-08-01","title":"[1.0.0-alpha.3] - 2023-08-01","text":""},{"location":"changelog/#added_6","title":"Added","text":"<ul> <li><code>origami.models.notebook.make_sql_cell</code> convenience function, returns a <code>CodeCell</code> with appropriate metadata</li> <li><code>rtu_client.change_cell_type</code> to switch between code, markdown, and sql cells</li> </ul>"},{"location":"changelog/#changed_6","title":"Changed","text":"<ul> <li><code>rtu_client.queue_execution</code> will always return a dict of {Future: cell_id}, even on single cell execution. Also guards against executing empty code cells</li> </ul>"},{"location":"changelog/#100-alpha2-2023-07-26","title":"[1.0.0-alpha.2] - 2023-07-26","text":""},{"location":"changelog/#changed_7","title":"Changed","text":"<ul> <li><code>api_client.rtu_client</code> method renamed to <code>api_client.connect_realtime</code>, can accept <code>File</code> model in addition to <code>str</code> / <code>UUID</code></li> </ul>"},{"location":"changelog/#100-alpha1-2023-07-25","title":"[1.0.0-alpha.1] - 2023-07-25","text":""},{"location":"changelog/#added_7","title":"Added","text":"<ul> <li><code>APIClient</code> and <code>RTUClient</code> for HTTP and Websocket connections to Noteables API respectively</li> <li>Discriminated-union Pydantic modeling for RTU and Delta payloads</li> <li>End-to-end tests to run against a Noteable deployment</li> </ul>"},{"location":"client/","title":"Noteable Client","text":"<p>The NoteableClient class provides an extension of <code>httpx.AsyncClient</code> with Noteable specific helpers. The async entrypoint for the class will establish and maintain a websocket for real time updates to/from Noteable servers. The API messages being sent have custom formats from Jupyter but for any directly connecting to the kernel pass Jupyter messages across the Noteable API layer. e.g. observing output messages arriving you'll see that their content matches the ZMQ Jupyter format.</p>"},{"location":"client/#authentication","title":"Authentication","text":"<p>The client automatically uses the <code>api_token</code> argument, or the <code>NOTEABLE_TOKEN</code> environment variable in absence, to generate the <code>f\"Bearer {self.token.access_token}\"</code> to establish connections or REST requests. This token can be an ephemeral token fetched dynamically from the site live with a short lifecycle, or you can create a more permanent token via your User Settings in the upper right of the Noteable platform. Either one will work as a Bearer token for authentication and can be individually revoked as needed.</p> <p>Note: If you have a custom deployment URL for your Noteable service, you'll need to set the <code>NOTEABLE_DOMAIN</code> environment variable or the <code>domain</code> config key to point to the correct URL. Otherwise it will default to the public multi-tenant environment.</p>"},{"location":"client/#routes","title":"Routes","text":"<p>Most routes presented help with kernel session or file manipulation. Some direct Jupyter APIs are also present on the server but not given helpers in the client as there's often a wrapping API preferred for use or replacing the open source pattern with Noteable specific affordances.</p> <p><code>get_or_launch_ready_kernel_session</code> is often where one will start to initiate or join a kernel session, handling the launch handshakes and establishing a connection to the Jupyter kernel. See the API docs page for the specific method signatures.</p> <p>You don't need to explicitly call <code>delete_kernel_session</code> but it does save on resources being utilized until they timeout on the service side. If you know you're wrapping up an interactions it's polite to clean the kernel and avoid wasting money / carbon.</p>"},{"location":"client/#websockets","title":"Websockets","text":"<p>Once aentered, the client will stream all messages back from the real time update channels. You can use <code>register_message_callback</code> to setup your own callbacks based on <code>message_type</code>, <code>transaction_id</code>, or response schemas. This is the primary way to respond to events in Noteable.</p> <p>Similarly, <code>send_rtu_request</code> is used to initiate any real time requests to the system. Common patterns using these calls are wrapped in helpers to achieve known patterns but any extensions can be added to customize client behavior using these mechanisms.</p> <p>See the API docs page for the specific method signatures related to these actions.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>When contributing to this repository, please first discuss the change you wish to make via issue, email, or any other method with the owners of this repository before making a change. </p> <p>Please note we have a code of conduct, please follow it in all your interactions with the project.</p>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Ensure tests pass before submitting a pull request.</li> <li>For non-trivial changes, ensure new tests are present before submitting a pull request.</li> <li>Update the README.md with details of changes to the interface, this includes new environment     variables, exposed ports, useful file locations and container parameters.</li> <li>You may merge the Pull Request in once you have the sign-off of one other developer, or if you     do not have permission to do that, you may request the reviewer to merge it for you.</li> </ol>"},{"location":"contributing/#local-setup","title":"Local setup","text":"<ol> <li>Fork this repository.</li> <li>Clone the forked repository.</li> <li>Change to the cloned directory.</li> <li>Ensure <code>poetry</code> is installed.</li> <li>Run <code>poetry install</code>.</li> <li>Run <code>nox -s test</code> to run all tests.</li> </ol>"},{"location":"contributing/#project-layout","title":"Project layout","text":"<p>The project strucute follows this pattern:</p> <pre><code>   pyproject.toml # The repository toml for setup instructions\n   mkdocs.yml     # Docs configuration file\n   docs/\n      index.md    # The documentation homepage.\n      ...         # Other markdown pages, images and other files\n   tests/\n      ...         # End-to-end tests against a Noteable cluster\n   origami/\n      clients/\n         api.py    # HTTP API Client for CRUD resources\n         rtu.py    # RTU Client for live Notebook document model updates and cell execution\n         cache.py  # RTU Client cache for interacting with multiple Notebooks\n      models/\n         rtu/      # Real-time-update websocket payload models\n         deltas/   # Document model updates within RTU Delta payloads\n      notebook/\n         ...       # In-memory Notebook builder that squashes RTU/Deltas\n</code></pre>"},{"location":"quickstart/","title":"Quick Start","text":"<p>The example below will guide you through the basics of creating a notebook, adding content, executing code, and seeing the output. For more examples, see our Use Cases section.</p> <p>Developer note: For pre-1.0 release information, see the pre-1.0 README</p>"},{"location":"quickstart/#installation","title":"Installation","text":"<p>For stable release:</p> <pre><code>pip install noteable-origami\n</code></pre> <pre><code>poetry add noteable-origami\n</code></pre> <p>For alpha pre-release:</p> <pre><code>pip install noteable-origami --pre\n</code></pre>"},{"location":"quickstart/#api-tokens","title":"API Tokens","text":"<p>The Noteable API requires an authentication token. You can manage tokens at the Noteable user settings page.</p> <ol> <li>Log in to Noteable (sign up is free).</li> <li>In the User Settings tab, navigate to <code>API Tokens</code> and generate a new token. </li> <li>Copy the generated token to the clipboard and save in a secure location, to be read into your Python environment later. </li> </ol> <p>The token can be passed directly in to <code>APIClient</code> on initialization, or set it as env var <code>NOTEABLE_TOKEN</code>.</p>"},{"location":"quickstart/#usage","title":"Usage","text":""},{"location":"quickstart/#setting-up-the-apiclient","title":"Setting up the <code>APIClient</code>","text":"<p>Using the API token you created previously, load it into your notebook environment so it can be passed into the <code>APIClient</code> directly. (If you're in Noteable, you can create a Secret that can be read in as an environment variable.)</p> <p><pre><code>import os\nfrom origami.clients.api import APIClient\n\n# if we have the `NOTEABLE_TOKEN` environment variable set,\n# we don't need to pass it in to the APIClient directly\napi_client = APIClient()\n</code></pre> The <code>APIClient</code> is what we'll use to make HTTP requests to Noteable's REST API.</p>"},{"location":"quickstart/#checking-your-user-information","title":"Checking your user information","text":"<p><pre><code>user = await api_client.user_info()\nuser\n</code></pre> <pre><code>User(\n    id=UUID('f1a2b3c4-5678-4d90-ef01-23456789abcd'),\n    created_at=datetime.datetime(2023, 1, 1, 0, 0, 0, 0, tzinfo=datetime.timezone.utc),\n    updated_at=datetime.datetime(2023, 1, 1, 0, 0, 0, 0, tzinfo=datetime.timezone.utc),\n    deleted_at=None,\n    handle='ori.gami',\n    email='origami@noteable.io',\n    first_name='Ori',\n    last_name='Gami',\n    origamist_default_project_id=UUID('a1b2c3d4-e5f6-4a7b-8123-abcdef123456'),\n    principal_sub='pat:0a1b2c3d4e5f6g7h8i9j10k11l',\n    auth_type='pat:0a1b2c3d4e5f6g7h8i9j10k11l'\n)\n</code></pre> (The information returned should match your user account information associated with the previously-generated API token.)</p>"},{"location":"quickstart/#creating-a-new-notebook","title":"Creating a new Notebook","text":"<p>For this example, we're using the <code>origamist_default_project_id</code>, which is the default project designed to be used by the ChatGPT plugin. Feel free to replace it with projects you have access to in Noteable!</p> <p>Provide a file <code>path</code> as well as a <code>project_id</code> (UUID) where the Notebook will exist. <pre><code>project_id = user.origamist_default_project_id\n\nfile = await api_client.create_notebook(\n    project_id=project_id,\n    path=\"Origami Demo.ipynb\"\n)\nfile\n</code></pre> <pre><code>File(\n    id=UUID('bcd12345-6789-4abc-d012-3456abcdef90'),\n    created_at=datetime.datetime(2023, 2, 2, 0, 0, 0, 0, tzinfo=datetime.timezone.utc),\n    updated_at=datetime.datetime(2023, 2, 2, 0, 0, 0, 0, tzinfo=datetime.timezone.utc),\n    deleted_at=None,\n    filename='Origami Demo.ipynb',\n    path=PosixPath('Origami Demo.ipynb'),\n    project_id=UUID('a1b2c3d4-e5f6-4a7b-8123-abcdef123456'),\n    space_id=UUID('7890ab12-3412-4cde-8901-2345abcdef67'),\n    size=0,\n    mimetype=None,\n    type='notebook',\n    current_version_id=None,\n    presigned_download_url=None,\n    url='https://app.noteable.io/f/abc12312-3412-4abc-8123-abc12312abc1/Origami Demo.ipynb'\n)\n</code></pre></p>"},{"location":"quickstart/#launching-a-kernel","title":"Launching a Kernel","text":"<p>At a minimum, the <code>file_id</code> from the Notebook is required. Additionally, you can specify:</p> <ul> <li><code>kernel_name</code> (default <code>python3</code>, see more about available kernels)</li> <li><code>hardware_size</code> (default <code>small</code>, see more about hardware options).</li> </ul> <p><pre><code>kernel_session = await api_client.launch_kernel(file_id=file.id)\nkernel_session\n</code></pre> <pre><code>KernelSession(\n    id=UUID('e1f2a345-6789-4b01-cdef-1234567890ab'),\n    kernel=KernelDetails(\n        name='python3',\n        last_activity=datetime.datetime(2023, 2, 2, 1, 0, 0, 0, tzinfo=datetime.timezone.utc),\n        execution_state='idle'\n    )\n)\n</code></pre></p>"},{"location":"quickstart/#adding-cells","title":"Adding Cells","text":"<p>Content updates and code execution is handled through the Noteable Real-Time Update (RTU) websocket connection. <pre><code>realtime_notebook = await api_client.connect_realtime(file)\n</code></pre></p> <p>You may see messages like <code>Received un-modeled RTU message msg.channel= ...</code>. This is expected as we update the Noteable backend services' messaging.</p> <p>Once the RTU client is connected, we can begin adding cells, executing code, and more! First, let's add a code cell with a basic Python <code>print</code> statement. <pre><code>from origami.models.notebook import CodeCell\n\ncell = CodeCell(source=\"print('Hello World')\")\nawait realtime_notebook.add_cell(cell=cell)\n</code></pre> (You can also pass code source directly into <code>.add_cell(source='CODE HERE')</code> as a shortcut.)</p>"},{"location":"quickstart/#running-a-code-cell","title":"Running a Code Cell","text":"<p>The returned value is a dictionary of <code>asyncio.Future</code>s. Awaiting those futures will block until the cells have completed execution. The return value of the Futures is the up-to-date cell. If there's output, an output collection id will be set on the cell metadata. <pre><code>import asyncio\n\nqueued_execution = await realtime_notebook.queue_execution(cell.id)\ncells = await asyncio.gather(*queued_execution)\ncell = cells[0]\ncell\n</code></pre> <pre><code>CodeCell(\n    id='2345ab6c-de78-4901-bcde-f1234567890a',\n    source=\"print('Hello World')\",\n    metadata={\n        'noteable': {'output_collection_id': UUID('d1234e5f-6789-4a0b-c123-4567890abcdef')},\n        'ExecuteTime': {\n            'start_time': '2023-02-02T01:00:00.000000+00:00',\n            'end_time': '2023-02-02T01:00:00.050000+00:00'\n        }\n    },\n    cell_type='code',\n    execution_count=None,\n    outputs=[]\n)\n</code></pre></p>"},{"location":"quickstart/#getting-cell-output","title":"Getting Cell Output","text":"<p>We can call the <code>.output_collection_id</code> property on cells directly, rather than having to parse the cell metadata. <pre><code>output_collection = await api_client.get_output_collection(cell.output_collection_id)\noutput_collection\n</code></pre> <pre><code>KernelOutputCollection(\n    id=UUID('d1234e5f-6789-4a0b-c123-4567890abcdef'),\n    created_at=datetime.datetime(2023, 2, 2, 1, 0, 1, 000000, tzinfo=datetime.timezone.utc),\n    updated_at=datetime.datetime(2023, 2, 2, 1, 0, 1, 000000, tzinfo=datetime.timezone.utc),\n    deleted_at=None,\n    cell_id='2345ab6c-de78-4901-bcde-f1234567890a',\n    widget_model_id=None,\n    file_id=UUID('bcd12345-6789-4abc-d012-3456abcdef90'),\n    outputs=[\n        KernelOutput(\n            id=UUID('abcdef90-1234-4a56-7890-abcdef123456'),\n            created_at=datetime.datetime(2023, 2, 2, 1, 0, 1, 000000, tzinfo=datetime.timezone.utc),\n            updated_at=datetime.datetime(2023, 2, 2, 1, 0, 1, 000000, tzinfo=datetime.timezone.utc),\n            deleted_at=None,\n            type='stream',\n            display_id=None,\n            available_mimetypes=['text/plain'],\n            content_metadata=KernelOutputContent(raw='{\"name\":\"stdout\"}', url=None, mimetype='application/json'),\n            content=KernelOutputContent(raw='Hello World\\n', url=None, mimetype='text/plain'),\n            content_for_llm=KernelOutputContent(raw='Hello World\\n', url=None, mimetype='text/plain'),\n            parent_collection_id=UUID('d1234e5f-6789-4a0b-c123-4567890abcdef')\n        )\n    ]\n)\n</code></pre></p>"},{"location":"usage/","title":"Use Cases","text":"<p>Coming soon!</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>cli</li> <li>clients<ul> <li>api</li> <li>cache</li> <li>rtu</li> </ul> </li> <li>log_utils</li> <li>models<ul> <li>api<ul> <li>base</li> <li>datasources</li> <li>files</li> <li>outputs</li> <li>projects</li> <li>spaces</li> <li>users</li> </ul> </li> <li>deltas<ul> <li>base</li> <li>delta_types<ul> <li>cell_contents</li> <li>cell_execute</li> <li>cell_metadata</li> <li>cell_output_collection</li> <li>nb_cells</li> <li>nb_metadata</li> </ul> </li> <li>discriminators</li> </ul> </li> <li>kernels</li> <li>notebook</li> <li>rtu<ul> <li>base</li> <li>channels<ul> <li>files</li> <li>kernels</li> <li>system</li> </ul> </li> <li>discriminators</li> <li>errors</li> </ul> </li> </ul> </li> <li>notebook<ul> <li>builder</li> </ul> </li> </ul>"},{"location":"reference/cli/","title":"cli","text":""},{"location":"reference/log_utils/","title":"log_utils","text":"<p>origami emits all of its messages using vanilla logging. The setup_logging() function below will structure origami (and any other loggers) to be streamed out using structlogs ConsoleRenderer. While this is useful to the origami repo in general, for instance in the CLI script and in tests, this function primarily serves as a template for how to set up structlog in your own application and configure it to structure both structlog-emitted messages (your app logs probably) and vanilla logging (origami logs).</p>"},{"location":"reference/clients/api/","title":"api","text":""},{"location":"reference/clients/api/#clients.api.APIClient","title":"<code>APIClient</code>","text":"Source code in <code>origami/clients/api.py</code> <pre><code>class APIClient:\n    def __init__(\n        self,\n        authorization_token: Optional[str] = None,\n        api_base_url: str = \"https://app.noteable.io/gate/api\",\n        headers: Optional[dict] = None,\n        transport: Optional[httpx.AsyncHTTPTransport] = None,\n        timeout: httpx.Timeout = httpx.Timeout(5.0),\n        creator_client_type: str = \"origami\",\n    ):\n        # jwt and api_base_url saved as attributes because they're re-used when creating rtu client\n        self.jwt = authorization_token or os.environ.get(\"NOTEABLE_TOKEN\")\n        if not self.jwt:\n            raise ValueError(\n                \"Must provide authorization_token or set NOTEABLE_TOKEN environment variable\"\n            )\n        self.api_base_url = os.environ.get(\"NOTEABLE_API_URL\", api_base_url)\n        self.headers = {\"Authorization\": f\"Bearer {self.jwt}\"}\n        if headers:\n            self.headers.update(headers)\n\n        self.client = httpx.AsyncClient(\n            base_url=self.api_base_url,\n            headers=self.headers,\n            transport=transport,\n            timeout=timeout,\n        )\n        # creator_client_type helps log what kind of client created Resources like Files/Projects\n        # or is interacting with Notebooks through RTU / Deltas. If you're not sure what to use\n        # yourself, go with the default 'origami'\n        if creator_client_type not in [\"origami\", \"origamist\", \"planar_ally\", \"geas\"]:\n            # this list of valid creator client types is sourced from Gate's FrontendType enum\n            creator_client_type = \"unknown\"\n        self.creator_client_type = creator_client_type  # Only used when generating an RTUClient\n\n    def add_tags_and_contextvars(self, **tags):\n        \"\"\"Hook for Apps to override so they can set structlog contextvars or ddtrace tags etc\"\"\"\n        pass\n\n    async def user_info(self) -&gt; User:\n        \"\"\"Get email and other info for User account of this Client's JWT.\"\"\"\n        endpoint = \"/users/me\"\n        resp = await self.client.get(endpoint)\n        resp.raise_for_status()\n        user = User.model_validate(resp.json())\n        self.add_tags_and_contextvars(user_id=str(user.id))\n        return user\n\n    async def share_resource(\n        self, resource: Resource, resource_id: uuid.UUID, email: str, level: Union[str, AccessLevel]\n    ) -&gt; int:\n        \"\"\"\n        Add another User as a collaborator to a Resource.\n        \"\"\"\n        user_lookup_endpoint = f\"/{resource.value}/{resource_id}/shareable-users\"\n        user_lookup_params = {\"q\": email}\n        user_lookup_resp = await self.client.get(user_lookup_endpoint, params=user_lookup_params)\n        user_lookup_resp.raise_for_status()\n        users = user_lookup_resp.json()[\"data\"]\n\n        if isinstance(level, str):\n            level = AccessLevel.from_str(level)\n        share_endpoint = f\"/{resource.value}/{resource_id}/users\"\n        for item in users:\n            user_id = item[\"id\"]\n            share_body = {\"access_level\": level.value, \"user_id\": user_id}\n            share_resp = await self.client.put(share_endpoint, json=share_body)\n            share_resp.raise_for_status()\n        return len(users)\n\n    async def unshare_resource(self, resource: Resource, resource_id: uuid.UUID, email: str) -&gt; int:\n        \"\"\"\n        Remove access to a Resource for a User\n        \"\"\"\n        # Need to look this up still to go from email to user-id\n        user_lookup_endpoint = f\"/{resource.value}/{resource_id}/shareable-users\"\n        user_lookup_params = {\"q\": email}\n        user_lookup_resp = await self.client.get(user_lookup_endpoint, params=user_lookup_params)\n        user_lookup_resp.raise_for_status()\n        users = user_lookup_resp.json()[\"data\"]\n\n        for item in users:\n            user_id = item[\"id\"]\n            unshare_endpoint = f\"/{resource.value}/{resource_id}/users/{user_id}\"\n            unshare_resp = await self.client.delete(unshare_endpoint)\n            unshare_resp.raise_for_status()\n        return len(users)\n\n    async def change_resource_visibility(\n        self,\n        resource: Resource,\n        resource_id: uuid.UUID,\n        visibility: Visibility,\n        visibility_default_access_level: Optional[AccessLevel] = None,\n    ):\n        \"\"\"\n        Change overall visibility of a Resource.\n\n        visibility_default_access_level is only required when visibility is not private.\n        \"\"\"\n        if isinstance(visibility, str):\n            visibility = Visibility.from_str(visibility)\n\n        if visibility is not Visibility.private and visibility_default_access_level is None:\n            raise ValueError(\n                \"visibility_default_access_level must be set when visibility is not private\"\n            )\n\n        patch_body = {\"visibility\": visibility.value}\n        if isinstance(visibility_default_access_level, str):\n            visibility_default_access_level = AccessLevel.from_str(\n                visibility_default_access_level\n            ).value\n\n        # always set this as either None or a valid (string) value\n        patch_body[\"visibility_default_access_level\"] = visibility_default_access_level\n\n        endpoint = f\"/{resource.value}/{resource_id}\"\n        resp = await self.client.patch(\n            endpoint,\n            json=patch_body,\n        )\n        resp.raise_for_status()\n        return resp.json()\n\n    # Spaces are collections of Projects. Some \"scoped\" resources such as Secrets and Datasources\n    # can also be attached to a Space and made available to all users of that Space.\n    async def create_space(self, name: str, description: Optional[str] = None) -&gt; Space:\n        endpoint = \"/spaces\"\n        resp = await self.client.post(endpoint, json={\"name\": name, \"description\": description})\n        resp.raise_for_status()\n        space = Space.model_validate(resp.json())\n        self.add_tags_and_contextvars(space_id=str(space.id))\n        return space\n\n    async def get_space(self, space_id: uuid.UUID) -&gt; Space:\n        self.add_tags_and_contextvars(space_id=str(space_id))\n        endpoint = f\"/spaces/{space_id}\"\n        resp = await self.client.get(endpoint)\n        resp.raise_for_status()\n        space = Space.model_validate(resp.json())\n        return space\n\n    async def delete_space(self, space_id: uuid.UUID) -&gt; None:\n        self.add_tags_and_contextvars(space_id=str(space_id))\n        endpoint = f\"/spaces/{space_id}\"\n        resp = await self.client.delete(endpoint)\n        resp.raise_for_status()\n        return None\n\n    async def list_space_projects(self, space_id: uuid.UUID) -&gt; List[Project]:\n        \"\"\"List all Projects in a Space.\"\"\"\n        self.add_tags_and_contextvars(space_id=str(space_id))\n        endpoint = f\"/spaces/{space_id}/projects\"\n        resp = await self.client.get(endpoint)\n        resp.raise_for_status()\n        projects = [Project.model_validate(project) for project in resp.json()]\n        return projects\n\n    async def share_space(\n        self, space_id: uuid.UUID, email: str, level: Union[str, AccessLevel]\n    ) -&gt; int:\n        \"\"\"\n        Add another user as a collaborator to a Space.\n        \"\"\"\n        return await self.share_resource(Resource.spaces, space_id, email, level)\n\n    async def unshare_space(self, space_id: uuid.UUID, email: str) -&gt; int:\n        \"\"\"\n        Remove access to a Space for a User\n        \"\"\"\n        return await self.unshare_resource(Resource.spaces, space_id, email)\n\n    async def change_space_visibility(\n        self,\n        space_id: uuid.UUID,\n        visibility: Visibility,\n        visibility_default_access_level: Optional[AccessLevel] = None,\n    ) -&gt; Visibility:\n        \"\"\"\n        Change overall visibility of a Space\n        \"\"\"\n        return await self.change_resource_visibility(\n            Resource.spaces,\n            space_id,\n            visibility,\n            visibility_default_access_level,\n        )\n\n    # Projects are collections of Files, including Notebooks. When a Kernel is launched for a\n    # Notebook, all Files in the Project are volume mounted into the Kernel container at startup.\n    async def create_project(\n        self, space_id: uuid.UUID, name: str, description: Optional[str] = None\n    ) -&gt; Project:\n        self.add_tags_and_contextvars(space_id=str(space_id))\n        endpoint = \"/projects\"\n        resp = await self.client.post(\n            endpoint,\n            json={\n                \"space_id\": str(space_id),\n                \"name\": name,\n                \"description\": description,\n                \"with_empty_notebook\": False,\n                \"creator_client_type\": self.creator_client_type,\n            },\n        )\n        resp.raise_for_status()\n        project = Project.model_validate(resp.json())\n        self.add_tags_and_contextvars(project_id=str(project.id))\n        return project\n\n    async def get_project(self, project_id: uuid.UUID) -&gt; Project:\n        self.add_tags_and_contextvars(project_id=str(project_id))\n        endpoint = f\"/projects/{project_id}\"\n        resp = await self.client.get(endpoint)\n        resp.raise_for_status()\n        project = Project.model_validate(resp.json())\n        return project\n\n    async def delete_project(self, project_id: uuid.UUID) -&gt; Project:\n        self.add_tags_and_contextvars(project_id=str(project_id))\n        endpoint = f\"/projects/{project_id}\"\n        resp = await self.client.delete(endpoint)\n        resp.raise_for_status()\n        project = Project.model_validate(resp.json())\n        return project\n\n    async def share_project(\n        self, project_id: uuid.UUID, email: str, level: Union[str, AccessLevel]\n    ) -&gt; int:\n        \"\"\"\n        Add another User as a collaborator to a Project.\n        \"\"\"\n        return await self.share_resource(Resource.projects, project_id, email, level)\n\n    async def unshare_project(self, project_id: uuid.UUID, email: str) -&gt; int:\n        \"\"\"\n        Remove access to a Project for a User\n        \"\"\"\n        return await self.unshare_resource(Resource.projects, project_id, email)\n\n    async def change_project_visibility(\n        self,\n        project_id: uuid.UUID,\n        visibility: Visibility,\n        visibility_default_access_level: Optional[AccessLevel] = None,\n    ) -&gt; Visibility:\n        \"\"\"\n        Change overall visibility of a Project\n        \"\"\"\n        return await self.change_resource_visibility(\n            Resource.projects,\n            project_id,\n            visibility,\n            visibility_default_access_level,\n        )\n\n    async def list_project_files(self, project_id: uuid.UUID) -&gt; List[File]:\n        \"\"\"List all Files in a Project. Files do not have presigned download urls included here.\"\"\"\n        self.add_tags_and_contextvars(project_id=str(project_id))\n        endpoint = f\"/projects/{project_id}/files\"\n        resp = await self.client.get(endpoint)\n        resp.raise_for_status()\n        files = [File.model_validate(file) for file in resp.json()]\n        return files\n\n    # Files are flat files (like text, csv, etc) or Notebooks.\n    async def _multi_step_file_create(\n        self,\n        project_id: uuid.UUID,\n        path: str,\n        file_type: Literal[\"file\", \"notebook\"],\n        content: bytes,\n    ) -&gt; File:\n        # Uploading files using the /v1/files endpoint is a multi-step process.\n        # 1. POST /v1/files to get a presigned upload url and file id\n        # 2. PUT the file content to the presigned upload url, save the etag\n        # 3. POST /v1/files/{file-id}/complete-upload with upload id / key / etag\n        # file_type is 'file' for all non-Notebook files, and 'notebook' for Notebooks\n        # (1) Reserve File in db\n        body = {\n            \"project_id\": str(project_id),\n            \"path\": path,\n            \"type\": file_type,\n            \"file_size_bytes\": len(content),\n            \"creator_client_type\": self.creator_client_type,\n        }\n        resp = await self.client.post(\"/v1/files\", json=body)\n        resp.raise_for_status()\n\n        # (1.5) parse response\n        js = resp.json()\n        upload_url = js[\"presigned_upload_url_info\"][\"parts\"][0][\"upload_url\"]\n        upload_id = js[\"presigned_upload_url_info\"][\"upload_id\"]\n        upload_key = js[\"presigned_upload_url_info\"][\"key\"]\n        file = File.model_validate(js)\n\n        # (2) Upload to pre-signed url\n        # TODO: remove this hack if/when we get containers in Skaffold to be able to translate\n        # localhost urls to the minio pod/container\n        if \"LOCAL_K8S\" in os.environ and bool(os.environ[\"LOCAL_K8S\"]):\n            upload_url = upload_url.replace(\"localhost\", \"minio\")\n        async with httpx.AsyncClient() as plain_client:\n            r = await plain_client.put(upload_url, content=content)\n            r.raise_for_status()\n\n        # (3) Tell API we finished uploading (returns 204)\n        etag = r.headers[\"etag\"].strip('\"')\n        body = {\n            \"upload_id\": upload_id,\n            \"key\": upload_key,\n            \"parts\": [{\"etag\": etag, \"part_number\": 1}],\n        }\n        endpoint = f\"/v1/files/{file.id}/complete-upload\"\n        r2 = await self.client.post(endpoint, json=body)\n        r2.raise_for_status()\n        return file\n\n    async def create_file(self, project_id: uuid.UUID, path: str, content: bytes) -&gt; File:\n        \"\"\"Create a non-Notebook File in a Project\"\"\"\n        self.add_tags_and_contextvars(project_id=str(project_id))\n        file = await self._multi_step_file_create(project_id, path, \"file\", content)\n        self.add_tags_and_contextvars(file_id=str(file.id))\n        logger.info(\"Created new file\", extra={\"file_id\": str(file.id)})\n        return file\n\n    async def create_notebook(\n        self, project_id: uuid.UUID, path: str, notebook: Optional[Notebook] = None\n    ) -&gt; File:\n        \"\"\"Create a Notebook in a Project\"\"\"\n        self.add_tags_and_contextvars(project_id=str(project_id))\n        if notebook is None:\n            notebook = Notebook()\n        content = notebook.model_dump_json().encode()\n        file = await self._multi_step_file_create(project_id, path, \"notebook\", content)\n        self.add_tags_and_contextvars(file_id=str(file.id))\n        logger.info(\"Created new notebook\", extra={\"file_id\": str(file.id)})\n        return file\n\n    async def get_file(self, file_id: uuid.UUID) -&gt; File:\n        \"\"\"Get metadata about a File, not including its content. Includes presigned download url.\"\"\"\n        self.add_tags_and_contextvars(file_id=str(file_id))\n        endpoint = f\"/v1/files/{file_id}\"\n        resp = await self.client.get(endpoint)\n        resp.raise_for_status()\n        file = File.model_validate(resp.json())\n        return file\n\n    async def get_file_content(self, file_id: uuid.UUID) -&gt; bytes:\n        \"\"\"Get the content of a File, including Notebooks.\"\"\"\n        self.add_tags_and_contextvars(file_id=str(file_id))\n        file = await self.get_file(file_id)\n        presigned_download_url = file.presigned_download_url\n        if not presigned_download_url:\n            raise ValueError(f\"File {file.id} does not have a presigned download url\")\n        # TODO: remove this hack if/when we get containers in Skaffold to be able to translate\n        # localhost urls to the minio pod/container\n        if \"LOCAL_K8S\" in os.environ and bool(os.environ[\"LOCAL_K8S\"]):\n            presigned_download_url = presigned_download_url.replace(\"localhost\", \"minio\")\n        async with httpx.AsyncClient() as plain_http_client:\n            resp = await plain_http_client.get(presigned_download_url)\n            resp.raise_for_status()\n        return resp.content\n\n    async def get_file_versions(self, file_id: uuid.UUID) -&gt; List[FileVersion]:\n        \"\"\"\n        List all versions of a File. The response includes presigned urls to download the content\n        of any previous version. Note when working with older versions, you do not want to establish\n        an RTUClient to \"catch up\" past that version.\n        \"\"\"\n        endpoint = f\"/files/{file_id}/versions\"\n        resp = await self.client.get(endpoint)\n        resp.raise_for_status()\n        versions = [FileVersion.model_validate(version) for version in resp.json()]\n        return versions\n\n    async def delete_file(self, file_id: uuid.UUID) -&gt; File:\n        self.add_tags_and_contextvars(file_id=str(file_id))\n        endpoint = f\"/v1/files/{file_id}\"\n        resp = await self.client.delete(endpoint)\n        resp.raise_for_status()\n        file = File.model_validate(resp.json())\n        return file\n\n    async def share_file(\n        self, file_id: uuid.UUID, email: str, level: Union[str, AccessLevel]\n    ) -&gt; int:\n        \"\"\"\n        Add another User as a collaborator to a Notebook or File.\n        \"\"\"\n        return await self.share_resource(Resource.files, file_id, email, level)\n\n    async def unshare_file(self, file_id: uuid.UUID, email: str) -&gt; int:\n        \"\"\"\n        Remove access to a Notebook or File for a User\n        \"\"\"\n        return await self.unshare_resource(Resource.files, file_id, email)\n\n    async def change_file_visibility(\n        self,\n        file_id: uuid.UUID,\n        visibility: Visibility,\n        visibility_default_access_level: Optional[AccessLevel] = None,\n    ) -&gt; Visibility:\n        \"\"\"\n        Change overall visibility of a Notebook or File\n        \"\"\"\n        return await self.change_resource_visibility(\n            Resource.files,\n            file_id,\n            visibility,\n            visibility_default_access_level,\n        )\n\n    async def get_datasources_for_notebook(self, file_id: uuid.UUID) -&gt; List[DataSource]:\n        \"\"\"Return a list of Datasources that can be used in SQL cells within a Notebook\"\"\"\n        self.add_tags_and_contextvars(file_id=str(file_id))\n        endpoint = f\"/v1/datasources/by_notebook/{file_id}\"\n        resp = await self.client.get(endpoint)\n        resp.raise_for_status()\n        datasources = pydantic.parse_obj_as(List[DataSource], resp.json())\n\n        return datasources\n\n    async def launch_kernel(\n        self, file_id: uuid.UUID, kernel_name: str = \"python3\", hardware_size: str = \"small\"\n    ) -&gt; KernelSession:\n        endpoint = \"/v1/sessions\"\n        data = {\n            \"file_id\": str(file_id),\n            \"kernel_config\": {\n                \"kernel_name\": kernel_name,\n                \"hardware_size_identifier\": hardware_size,\n            },\n        }\n        resp = await self.client.post(endpoint, json=data)\n        resp.raise_for_status()\n        kernel_session = KernelSession.model_validate(resp.json())\n        self.add_tags_and_contextvars(kernel_session_id=str(kernel_session.id))\n        logger.info(\n            \"Launched new kernel\",\n            extra={\"kernel_session_id\": str(kernel_session.id), \"file_id\": str(file_id)},\n        )\n        return kernel_session\n\n    async def shutdown_kernel(self, kernel_session_id: uuid.UUID) -&gt; None:\n        endpoint = f\"/sessions/{kernel_session_id}\"\n        resp = await self.client.delete(endpoint, timeout=60)\n        resp.raise_for_status()\n        logger.info(\"Shut down kernel\", extra={\"kernel_session_id\": str(kernel_session_id)})\n\n    async def get_output_collection(\n        self, output_collection_id: uuid.UUID\n    ) -&gt; KernelOutputCollection:\n        endpoint = f\"/outputs/collection/{output_collection_id}\"\n        resp = await self.client.get(endpoint)\n        resp.raise_for_status()\n        return KernelOutputCollection.model_validate(resp.json())\n\n    async def connect_realtime(self, file: Union[File, uuid.UUID, str]) -&gt; \"RTUClient\":  # noqa\n        \"\"\"\n        Create an RTUClient for a Notebook by file id. This will perform the following steps:\n         - Check /v1/files to get the current version information and presigned download url\n         - Download seed notebook and create a NotebookBuilder from it\n         - Create an RTUClient, initialize the websocket connection, authenticate, and subscribe\n         - Apply delts to in-memory NotebookBuilder\n        \"\"\"\n        # Import here to avoid circular imports\n        from origami.clients.rtu import RTUClient\n\n        file_id = None\n\n        if isinstance(file, str):\n            file_id = uuid.UUID(file)\n        elif isinstance(file, uuid.UUID):\n            file_id = file\n        elif isinstance(file, File):\n            file_id = file.id\n        else:\n            raise ValueError(f\"Must provide a `file_id` or a File, not {file}\")\n\n        self.add_tags_and_contextvars(file_id=str(file_id))\n\n        logger.info(f\"Creating RTUClient for file {file_id}\")\n        rtu_client = RTUClient(api_client=self, file_id=file_id)\n        # .initialize() downloads the seed notebook, establishes websocket, subscribes to various\n        # channels, and begins squashing deltas.\n        await rtu_client.initialize()\n        # This event is resolved once all deltas from the file_subscribe reply deltas_to_apply\n        # payload have been applied to the RTUClient NotebookBuilder\n        await rtu_client.deltas_to_apply_event.wait()\n        return rtu_client\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.add_tags_and_contextvars","title":"<code>add_tags_and_contextvars(**tags)</code>","text":"<p>Hook for Apps to override so they can set structlog contextvars or ddtrace tags etc</p> Source code in <code>origami/clients/api.py</code> <pre><code>def add_tags_and_contextvars(self, **tags):\n    \"\"\"Hook for Apps to override so they can set structlog contextvars or ddtrace tags etc\"\"\"\n    pass\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.change_file_visibility","title":"<code>change_file_visibility(file_id, visibility, visibility_default_access_level=None)</code>  <code>async</code>","text":"<p>Change overall visibility of a Notebook or File</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def change_file_visibility(\n    self,\n    file_id: uuid.UUID,\n    visibility: Visibility,\n    visibility_default_access_level: Optional[AccessLevel] = None,\n) -&gt; Visibility:\n    \"\"\"\n    Change overall visibility of a Notebook or File\n    \"\"\"\n    return await self.change_resource_visibility(\n        Resource.files,\n        file_id,\n        visibility,\n        visibility_default_access_level,\n    )\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.change_project_visibility","title":"<code>change_project_visibility(project_id, visibility, visibility_default_access_level=None)</code>  <code>async</code>","text":"<p>Change overall visibility of a Project</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def change_project_visibility(\n    self,\n    project_id: uuid.UUID,\n    visibility: Visibility,\n    visibility_default_access_level: Optional[AccessLevel] = None,\n) -&gt; Visibility:\n    \"\"\"\n    Change overall visibility of a Project\n    \"\"\"\n    return await self.change_resource_visibility(\n        Resource.projects,\n        project_id,\n        visibility,\n        visibility_default_access_level,\n    )\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.change_resource_visibility","title":"<code>change_resource_visibility(resource, resource_id, visibility, visibility_default_access_level=None)</code>  <code>async</code>","text":"<p>Change overall visibility of a Resource.</p> <p>visibility_default_access_level is only required when visibility is not private.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def change_resource_visibility(\n    self,\n    resource: Resource,\n    resource_id: uuid.UUID,\n    visibility: Visibility,\n    visibility_default_access_level: Optional[AccessLevel] = None,\n):\n    \"\"\"\n    Change overall visibility of a Resource.\n\n    visibility_default_access_level is only required when visibility is not private.\n    \"\"\"\n    if isinstance(visibility, str):\n        visibility = Visibility.from_str(visibility)\n\n    if visibility is not Visibility.private and visibility_default_access_level is None:\n        raise ValueError(\n            \"visibility_default_access_level must be set when visibility is not private\"\n        )\n\n    patch_body = {\"visibility\": visibility.value}\n    if isinstance(visibility_default_access_level, str):\n        visibility_default_access_level = AccessLevel.from_str(\n            visibility_default_access_level\n        ).value\n\n    # always set this as either None or a valid (string) value\n    patch_body[\"visibility_default_access_level\"] = visibility_default_access_level\n\n    endpoint = f\"/{resource.value}/{resource_id}\"\n    resp = await self.client.patch(\n        endpoint,\n        json=patch_body,\n    )\n    resp.raise_for_status()\n    return resp.json()\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.change_space_visibility","title":"<code>change_space_visibility(space_id, visibility, visibility_default_access_level=None)</code>  <code>async</code>","text":"<p>Change overall visibility of a Space</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def change_space_visibility(\n    self,\n    space_id: uuid.UUID,\n    visibility: Visibility,\n    visibility_default_access_level: Optional[AccessLevel] = None,\n) -&gt; Visibility:\n    \"\"\"\n    Change overall visibility of a Space\n    \"\"\"\n    return await self.change_resource_visibility(\n        Resource.spaces,\n        space_id,\n        visibility,\n        visibility_default_access_level,\n    )\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.connect_realtime","title":"<code>connect_realtime(file)</code>  <code>async</code>","text":"<p>Create an RTUClient for a Notebook by file id. This will perform the following steps:  - Check /v1/files to get the current version information and presigned download url  - Download seed notebook and create a NotebookBuilder from it  - Create an RTUClient, initialize the websocket connection, authenticate, and subscribe  - Apply delts to in-memory NotebookBuilder</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def connect_realtime(self, file: Union[File, uuid.UUID, str]) -&gt; \"RTUClient\":  # noqa\n    \"\"\"\n    Create an RTUClient for a Notebook by file id. This will perform the following steps:\n     - Check /v1/files to get the current version information and presigned download url\n     - Download seed notebook and create a NotebookBuilder from it\n     - Create an RTUClient, initialize the websocket connection, authenticate, and subscribe\n     - Apply delts to in-memory NotebookBuilder\n    \"\"\"\n    # Import here to avoid circular imports\n    from origami.clients.rtu import RTUClient\n\n    file_id = None\n\n    if isinstance(file, str):\n        file_id = uuid.UUID(file)\n    elif isinstance(file, uuid.UUID):\n        file_id = file\n    elif isinstance(file, File):\n        file_id = file.id\n    else:\n        raise ValueError(f\"Must provide a `file_id` or a File, not {file}\")\n\n    self.add_tags_and_contextvars(file_id=str(file_id))\n\n    logger.info(f\"Creating RTUClient for file {file_id}\")\n    rtu_client = RTUClient(api_client=self, file_id=file_id)\n    # .initialize() downloads the seed notebook, establishes websocket, subscribes to various\n    # channels, and begins squashing deltas.\n    await rtu_client.initialize()\n    # This event is resolved once all deltas from the file_subscribe reply deltas_to_apply\n    # payload have been applied to the RTUClient NotebookBuilder\n    await rtu_client.deltas_to_apply_event.wait()\n    return rtu_client\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.create_file","title":"<code>create_file(project_id, path, content)</code>  <code>async</code>","text":"<p>Create a non-Notebook File in a Project</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def create_file(self, project_id: uuid.UUID, path: str, content: bytes) -&gt; File:\n    \"\"\"Create a non-Notebook File in a Project\"\"\"\n    self.add_tags_and_contextvars(project_id=str(project_id))\n    file = await self._multi_step_file_create(project_id, path, \"file\", content)\n    self.add_tags_and_contextvars(file_id=str(file.id))\n    logger.info(\"Created new file\", extra={\"file_id\": str(file.id)})\n    return file\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.create_notebook","title":"<code>create_notebook(project_id, path, notebook=None)</code>  <code>async</code>","text":"<p>Create a Notebook in a Project</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def create_notebook(\n    self, project_id: uuid.UUID, path: str, notebook: Optional[Notebook] = None\n) -&gt; File:\n    \"\"\"Create a Notebook in a Project\"\"\"\n    self.add_tags_and_contextvars(project_id=str(project_id))\n    if notebook is None:\n        notebook = Notebook()\n    content = notebook.model_dump_json().encode()\n    file = await self._multi_step_file_create(project_id, path, \"notebook\", content)\n    self.add_tags_and_contextvars(file_id=str(file.id))\n    logger.info(\"Created new notebook\", extra={\"file_id\": str(file.id)})\n    return file\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.get_datasources_for_notebook","title":"<code>get_datasources_for_notebook(file_id)</code>  <code>async</code>","text":"<p>Return a list of Datasources that can be used in SQL cells within a Notebook</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def get_datasources_for_notebook(self, file_id: uuid.UUID) -&gt; List[DataSource]:\n    \"\"\"Return a list of Datasources that can be used in SQL cells within a Notebook\"\"\"\n    self.add_tags_and_contextvars(file_id=str(file_id))\n    endpoint = f\"/v1/datasources/by_notebook/{file_id}\"\n    resp = await self.client.get(endpoint)\n    resp.raise_for_status()\n    datasources = pydantic.parse_obj_as(List[DataSource], resp.json())\n\n    return datasources\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.get_file","title":"<code>get_file(file_id)</code>  <code>async</code>","text":"<p>Get metadata about a File, not including its content. Includes presigned download url.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def get_file(self, file_id: uuid.UUID) -&gt; File:\n    \"\"\"Get metadata about a File, not including its content. Includes presigned download url.\"\"\"\n    self.add_tags_and_contextvars(file_id=str(file_id))\n    endpoint = f\"/v1/files/{file_id}\"\n    resp = await self.client.get(endpoint)\n    resp.raise_for_status()\n    file = File.model_validate(resp.json())\n    return file\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.get_file_content","title":"<code>get_file_content(file_id)</code>  <code>async</code>","text":"<p>Get the content of a File, including Notebooks.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def get_file_content(self, file_id: uuid.UUID) -&gt; bytes:\n    \"\"\"Get the content of a File, including Notebooks.\"\"\"\n    self.add_tags_and_contextvars(file_id=str(file_id))\n    file = await self.get_file(file_id)\n    presigned_download_url = file.presigned_download_url\n    if not presigned_download_url:\n        raise ValueError(f\"File {file.id} does not have a presigned download url\")\n    # TODO: remove this hack if/when we get containers in Skaffold to be able to translate\n    # localhost urls to the minio pod/container\n    if \"LOCAL_K8S\" in os.environ and bool(os.environ[\"LOCAL_K8S\"]):\n        presigned_download_url = presigned_download_url.replace(\"localhost\", \"minio\")\n    async with httpx.AsyncClient() as plain_http_client:\n        resp = await plain_http_client.get(presigned_download_url)\n        resp.raise_for_status()\n    return resp.content\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.get_file_versions","title":"<code>get_file_versions(file_id)</code>  <code>async</code>","text":"<p>List all versions of a File. The response includes presigned urls to download the content of any previous version. Note when working with older versions, you do not want to establish an RTUClient to \"catch up\" past that version.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def get_file_versions(self, file_id: uuid.UUID) -&gt; List[FileVersion]:\n    \"\"\"\n    List all versions of a File. The response includes presigned urls to download the content\n    of any previous version. Note when working with older versions, you do not want to establish\n    an RTUClient to \"catch up\" past that version.\n    \"\"\"\n    endpoint = f\"/files/{file_id}/versions\"\n    resp = await self.client.get(endpoint)\n    resp.raise_for_status()\n    versions = [FileVersion.model_validate(version) for version in resp.json()]\n    return versions\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.list_project_files","title":"<code>list_project_files(project_id)</code>  <code>async</code>","text":"<p>List all Files in a Project. Files do not have presigned download urls included here.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def list_project_files(self, project_id: uuid.UUID) -&gt; List[File]:\n    \"\"\"List all Files in a Project. Files do not have presigned download urls included here.\"\"\"\n    self.add_tags_and_contextvars(project_id=str(project_id))\n    endpoint = f\"/projects/{project_id}/files\"\n    resp = await self.client.get(endpoint)\n    resp.raise_for_status()\n    files = [File.model_validate(file) for file in resp.json()]\n    return files\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.list_space_projects","title":"<code>list_space_projects(space_id)</code>  <code>async</code>","text":"<p>List all Projects in a Space.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def list_space_projects(self, space_id: uuid.UUID) -&gt; List[Project]:\n    \"\"\"List all Projects in a Space.\"\"\"\n    self.add_tags_and_contextvars(space_id=str(space_id))\n    endpoint = f\"/spaces/{space_id}/projects\"\n    resp = await self.client.get(endpoint)\n    resp.raise_for_status()\n    projects = [Project.model_validate(project) for project in resp.json()]\n    return projects\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.share_file","title":"<code>share_file(file_id, email, level)</code>  <code>async</code>","text":"<p>Add another User as a collaborator to a Notebook or File.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def share_file(\n    self, file_id: uuid.UUID, email: str, level: Union[str, AccessLevel]\n) -&gt; int:\n    \"\"\"\n    Add another User as a collaborator to a Notebook or File.\n    \"\"\"\n    return await self.share_resource(Resource.files, file_id, email, level)\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.share_project","title":"<code>share_project(project_id, email, level)</code>  <code>async</code>","text":"<p>Add another User as a collaborator to a Project.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def share_project(\n    self, project_id: uuid.UUID, email: str, level: Union[str, AccessLevel]\n) -&gt; int:\n    \"\"\"\n    Add another User as a collaborator to a Project.\n    \"\"\"\n    return await self.share_resource(Resource.projects, project_id, email, level)\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.share_resource","title":"<code>share_resource(resource, resource_id, email, level)</code>  <code>async</code>","text":"<p>Add another User as a collaborator to a Resource.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def share_resource(\n    self, resource: Resource, resource_id: uuid.UUID, email: str, level: Union[str, AccessLevel]\n) -&gt; int:\n    \"\"\"\n    Add another User as a collaborator to a Resource.\n    \"\"\"\n    user_lookup_endpoint = f\"/{resource.value}/{resource_id}/shareable-users\"\n    user_lookup_params = {\"q\": email}\n    user_lookup_resp = await self.client.get(user_lookup_endpoint, params=user_lookup_params)\n    user_lookup_resp.raise_for_status()\n    users = user_lookup_resp.json()[\"data\"]\n\n    if isinstance(level, str):\n        level = AccessLevel.from_str(level)\n    share_endpoint = f\"/{resource.value}/{resource_id}/users\"\n    for item in users:\n        user_id = item[\"id\"]\n        share_body = {\"access_level\": level.value, \"user_id\": user_id}\n        share_resp = await self.client.put(share_endpoint, json=share_body)\n        share_resp.raise_for_status()\n    return len(users)\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.share_space","title":"<code>share_space(space_id, email, level)</code>  <code>async</code>","text":"<p>Add another user as a collaborator to a Space.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def share_space(\n    self, space_id: uuid.UUID, email: str, level: Union[str, AccessLevel]\n) -&gt; int:\n    \"\"\"\n    Add another user as a collaborator to a Space.\n    \"\"\"\n    return await self.share_resource(Resource.spaces, space_id, email, level)\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.unshare_file","title":"<code>unshare_file(file_id, email)</code>  <code>async</code>","text":"<p>Remove access to a Notebook or File for a User</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def unshare_file(self, file_id: uuid.UUID, email: str) -&gt; int:\n    \"\"\"\n    Remove access to a Notebook or File for a User\n    \"\"\"\n    return await self.unshare_resource(Resource.files, file_id, email)\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.unshare_project","title":"<code>unshare_project(project_id, email)</code>  <code>async</code>","text":"<p>Remove access to a Project for a User</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def unshare_project(self, project_id: uuid.UUID, email: str) -&gt; int:\n    \"\"\"\n    Remove access to a Project for a User\n    \"\"\"\n    return await self.unshare_resource(Resource.projects, project_id, email)\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.unshare_resource","title":"<code>unshare_resource(resource, resource_id, email)</code>  <code>async</code>","text":"<p>Remove access to a Resource for a User</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def unshare_resource(self, resource: Resource, resource_id: uuid.UUID, email: str) -&gt; int:\n    \"\"\"\n    Remove access to a Resource for a User\n    \"\"\"\n    # Need to look this up still to go from email to user-id\n    user_lookup_endpoint = f\"/{resource.value}/{resource_id}/shareable-users\"\n    user_lookup_params = {\"q\": email}\n    user_lookup_resp = await self.client.get(user_lookup_endpoint, params=user_lookup_params)\n    user_lookup_resp.raise_for_status()\n    users = user_lookup_resp.json()[\"data\"]\n\n    for item in users:\n        user_id = item[\"id\"]\n        unshare_endpoint = f\"/{resource.value}/{resource_id}/users/{user_id}\"\n        unshare_resp = await self.client.delete(unshare_endpoint)\n        unshare_resp.raise_for_status()\n    return len(users)\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.unshare_space","title":"<code>unshare_space(space_id, email)</code>  <code>async</code>","text":"<p>Remove access to a Space for a User</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def unshare_space(self, space_id: uuid.UUID, email: str) -&gt; int:\n    \"\"\"\n    Remove access to a Space for a User\n    \"\"\"\n    return await self.unshare_resource(Resource.spaces, space_id, email)\n</code></pre>"},{"location":"reference/clients/api/#clients.api.APIClient.user_info","title":"<code>user_info()</code>  <code>async</code>","text":"<p>Get email and other info for User account of this Client's JWT.</p> Source code in <code>origami/clients/api.py</code> <pre><code>async def user_info(self) -&gt; User:\n    \"\"\"Get email and other info for User account of this Client's JWT.\"\"\"\n    endpoint = \"/users/me\"\n    resp = await self.client.get(endpoint)\n    resp.raise_for_status()\n    user = User.model_validate(resp.json())\n    self.add_tags_and_contextvars(user_id=str(user.id))\n    return user\n</code></pre>"},{"location":"reference/clients/api/#clients.api.Visibility","title":"<code>Visibility</code>","text":"<p>             Bases: <code>Enum</code></p> <p>Visibility levels associated with a specific Resource.</p> <p>Private = only invited users can access Open = any member can access Public = anyone can access</p> Source code in <code>origami/clients/api.py</code> <pre><code>class Visibility(enum.Enum):\n    \"\"\"Visibility levels associated with a specific Resource.\n\n    Private = only invited users can access\n    Open = any member can access\n    Public = anyone can access\n    \"\"\"\n\n    private = \"private\"\n    open = \"open\"\n    public = \"public\"\n\n    @classmethod\n    def from_str(cls, s: str):\n        for vis in cls:\n            if vis.name == s:\n                return vis\n        raise ValueError(f\"Invalid visibility {s}\")\n</code></pre>"},{"location":"reference/clients/cache/","title":"cache","text":""},{"location":"reference/clients/rtu/","title":"rtu","text":"<p>RTUClient is a high-level client for establishing a websocket connection, authenticating with a jwt, subscribing to a file by version or last delta id, \"squashing\" Deltas into an in-memory Notebook model, and registering callbacks for incoming RTU events by event_name and channel or incoming Deltas by delta type and delta action.</p>"},{"location":"reference/clients/rtu/#clients.rtu.DeltaRequestCallbackManager","title":"<code>DeltaRequestCallbackManager</code>","text":"<p>Don't use this directly, see RTUClient.new_delta_request which builds an instance of this and returns the .result -- Future resolves to bool or raises DeltaRejected</p> <ul> <li>Sends over websocket to Gate</li> <li>Registers RTU and Delta squashing callbacks to resolve the Future either when the Delta was   successful and squashed into Notebook or when there was an error (Rejected / Invalid Delta)</li> <li>Deregisters RTU and Delta callbacks when Future is resolved</li> </ul> <p>Use case: delta_squashed: asyncio.Future[bool] = await rtu_client.new_delta_request(...) try:     await delta_squashed except DeltaRejected:     ...</p>"},{"location":"reference/clients/rtu/#clients.rtu.DeltaRequestCallbackManager--delta-is-guarenteed-to-be-in-rtu_clientbuilder-at-this-point","title":"Delta is guarenteed to be in rtu_client.builder at this point","text":"Source code in <code>origami/clients/rtu.py</code> <pre><code>class DeltaRequestCallbackManager:\n    \"\"\"\n    Don't use this directly, see RTUClient.new_delta_request which builds an instance of this and\n    returns the .result -- Future resolves to bool or raises DeltaRejected\n\n    - Sends over websocket to Gate\n    - Registers RTU and Delta squashing callbacks to resolve the Future either when the Delta was\n      successful and squashed into Notebook or when there was an error (Rejected / Invalid Delta)\n    - Deregisters RTU and Delta callbacks when Future is resolved\n\n    Use case:\n    delta_squashed: asyncio.Future[bool] = await rtu_client.new_delta_request(...)\n    try:\n        await delta_squashed\n    except DeltaRejected:\n        ...\n    # Delta is guarenteed to be in rtu_client.builder at this point\n    \"\"\"\n\n    def __init__(self, client: \"RTUClient\", delta: FileDelta):\n        self.result = asyncio.Future()\n        self.client = client\n        self.delta = delta  # keep a ref to use in self.delta_cb_ref\n        req = NewDeltaRequest(\n            channel=f\"files/{self.client.file_id}\", data=NewDeltaRequestData(delta=delta)\n        )\n        # Register one cb by RTU request transaction id in order to catch errors and set Future\n        self.rtu_cb_ref = client.register_transaction_id_callback(\n            transaction_id=req.transaction_id, fn=self.rtu_cb\n        )\n        # Register other cb by Delta type so we'll be able to resolve future when it's squashed\n        self.delta_cb_ref = client.register_delta_callback(\n            delta_class=type(delta), fn=self.delta_cb\n        )\n        client.send(req)\n\n    def deregister_callbacks(self):\n        self.rtu_cb_ref()  # deregisters the callback from Sending managed list\n        self.client.delta_callbacks.remove(self.delta_cb_ref)  # Remove from delta cb list\n\n    async def rtu_cb(self, msg: RTUResponse):\n        # If the delta is rejected, we should see a new_delta_reply with success=False and the\n        # details are in a separate delta_rejected event\n        if msg.event == \"delta_rejected\":\n            logger.debug(\"Delta rejected\", extra={\"rtu_msg\": msg})\n            self.result.set_exception(DeltaRejected(msg.data[\"cause\"]))\n            self.deregister_callbacks()\n\n        elif msg.event == \"invalid_data\":\n            # If Gate can't parse the Delta into Pydantic model, it will give back this invalid_data\n            # event, but it doesn't include the validation details in the body. Need to look at\n            # Gate logs to see what happened (like nb_cells add not having 'id' in properties)\n            logger.debug(\"Delta invalid\", extra={\"rtu_msg\": msg})\n            self.result.set_exception(DeltaRejected(\"Invalid Delta scheme\"))\n            self.deregister_callbacks()\n\n        elif msg.event == \"permission_denied\":\n            logger.debug(\"Delta permission denied\", extra={\"rtu_msg\": msg})\n            self.result.set_exception(DeltaRejected(\"Permission denied\"))\n            self.deregister_callbacks()\n\n    async def delta_cb(self, delta: FileDelta):\n        if delta.id == self.delta.id:\n            logger.debug(\"Delta squashed\", extra={\"delta\": delta})\n            if not self.result.done():\n                self.result.set_result(delta)\n            self.deregister_callbacks()\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient","title":"<code>RTUClient</code>","text":"Source code in <code>origami/clients/rtu.py</code> <pre><code>class RTUClient:\n    def __init__(\n        self,\n        api_client: APIClient,\n        file_id: uuid.UUID,\n        file_subscribe_timeout: int = 10,\n    ):\n        \"\"\"\n        High-level client over the Sending websocket backend / RTUManager (serialize websocket msgs\n        to/from RTU models) that allows you to add callbacks by RTU event type or Delta type/action.\n\n        - On .initialize(), will make a websocket connection to Gate\n          - RTUManager / Sending websocket backend handles reconnection\n          - RTUClient sets .manager.auth_hook to kick off the auth request, don't override that\n          - awaits .on_websocket_connect() hook that you can override in application code\n\n        - After websocket connection is established, sends authenticate_request on system channel\n          - Has a callback registered for 'authenticate_reply' on system channel which will\n            await .on_auth (hook to define in application code) then send file subscribe request\n\n        - After authentication, sends subscribe_request to files/{file_id} channel\n          - awaits .on_file_subscribe() hook that you can override in application code\n\n        - Use .register_rtu_event_callback to register callbacks that are run against RTU messages\n\n        - Use .register_delta_callback to register callbacks that are run against Deltas\n          - May not run when message is initially received if the Delta is \"out of order\", RTUClient\n            handles queueing and replaying out of order deltas\n          - Callbacks run after the Delta is \"squashed\" into {builder}\n        \"\"\"\n        self.api_client = api_client\n\n        rtu_url = (\n            os.environ.get(\"NOTEABLE_RTU_URL\")\n            or api_client.api_base_url.replace(\"http\", \"ws\") + \"/v1/rtu\"\n        )\n        self.manager = RTUManager(ws_url=rtu_url)  # Sending websocket backend w/ RTU serialization\n        self.file_id = file_id\n\n        self.rtu_session_id = None  # Set after establishing websocket connection on .initialize()\n        self.builder = None  # Set from .build_notebook, called as part of .initialize()\n        self.user_id = None  # set during authenticate_reply handling, used in new_delta_request\n\n        # When we send file subscribe request, it'll create a task to run .on_file_subscribe_timeout\n        # which should blow up the RTU Client. Otherwise we can get stuck indefinitely waiting\n        # for .deltas_to_apply event. If we get through initialization okay, the task will cancel\n        self.file_subcribe_timeout = file_subscribe_timeout\n        self.file_subscribe_timeout_task: Optional[asyncio.Task] = None\n\n        # Callbacks triggered from Sending based on websocket connection lifecycle events\n        self.manager.auth_hook = self.auth_hook\n        self.manager.connect_hook = self.connect_hook\n        self.manager.context_hook = self.context_hook\n        self.manager.disconnect_hook = self.disconnect_hook\n\n        # Callbacks that are part of the startup flow (auth and File subscribe)\n        self.register_rtu_event_callback(rtu_event=AuthenticateReply, fn=self._on_auth)\n        self.register_rtu_event_callback(\n            rtu_event=FileSubscribeReply, fn=self._on_file_subscribe_reply\n        )\n\n        # Incoming Delta handling. Key points here are:\n        # - we don't want to squash deltas until we get file subscribe reply and deltas-to-apply\n        # - Deltas may be \"out of order\", should save to be replayed later\n        # - When finally applying Delta \"in order\", then we await callbacks by delta type/action\n        # See self.new_delta_request for more details on sending out Deltas\n        self.delta_callbacks: List[DeltaCallback] = []\n        self.unapplied_deltas: List[FileDelta] = []  # \"out of order deltas\" to be replayed\n        self.deltas_to_apply_event = asyncio.Event()  # set in ._on_file_subscribe_reply\n\n        self.register_rtu_event_callback(rtu_event=NewDeltaEvent, fn=self._on_delta_recv)\n\n        # Kernel and cell state handling\n        self.kernel_state: str = \"not_started\"  # value used when there's no Kernel for a Notebook\n        self.cell_states: Dict[str, str] = {}\n\n        self.register_rtu_event_callback(\n            rtu_event=KernelStatusUpdateResponse, fn=self.on_kernel_status_update\n        )\n        self.register_rtu_event_callback(\n            rtu_event=BulkCellStateUpdateResponse, fn=self.on_bulk_cell_state_update\n        )\n\n        # An inconsistent state event means the Notebook was updated in a way that \"broke\" Delta\n        # history, and the RTUClient needs to pull in the seed notebook and re-apply deltas from\n        # a \"new\" current version id in order to catch up\n        #\n        # However if we get several inconsistent state events (say from getting them on file\n        # resubscribe), we'll call catastrophic_failure to let the application handle tear-down\n        self.inconsistent_state_event_count = 0\n        self.register_rtu_event_callback(\n            rtu_event=InconsistentStateEvent, fn=self.on_inconsistent_state_event\n        )\n\n        # Log anytime we get an un-modeled RTU message.\n        # Not going through register_rtu_event_callback because isinstance would catch child classes\n        def predicate_fn(topic: Literal[\"\"], msg: RTUResponse):\n            return type(msg) == BaseRTUResponse\n\n        self.manager.register_callback(self._on_unmodeled_rtu_msg, on_predicate=predicate_fn)\n\n        # When someone calls .execute_cell, return an asyncio.Future that will be resolved to be\n        # the updated Cell model when the cell is done executing\n        self._execute_cell_events: Dict[str, asyncio.Future[CodeCell]] = {}\n\n    async def catastrophic_failure(self):\n        \"\"\"\n        A hook for applications like PA to override so they can handle things like Pod shutdown\n        in cases where the RTUClient cannot recover. Examples are when reloading Notebook state\n        after inconsistent_state_event and not getting a current_version_id to subscribe by or\n        getting Deltas that cannot be squashed into the builder\n        \"\"\"\n        logger.warning(\"Catastrophic failure, RTU applications can override this hook\")\n\n    @property\n    def cell_ids(self):\n        \"\"\"Return list of cell_id's in order from NotebookBuilder in-memory model\"\"\"\n        return [cell.id for cell in self.builder.nb.cells]\n\n    @property\n    def kernel_pod_name(self) -&gt; str:\n        \"\"\"Transform the file_id into the Pod name used to build the kernels/ RTU channel\"\"\"\n        return f\"kernels/notebook-kernel-{self.file_id.hex[:20]}\"\n\n    def send(self, msg: RTURequest):\n        \"\"\"\n        Send an RTU message to Noteable. This is not async because what's happening behind the\n        scenes is that RTUManager.send drops the RTU pydantic model onto an \"outbound\" asyncio.Queue\n        then the \"outbound worker\" picks it up off the queue, serializes it to JSON, and sends it\n        out over the wire.\n        \"\"\"\n        self.manager.send(msg)\n\n    async def _on_unmodeled_rtu_msg(self, msg: BaseRTUResponse):\n        logger.warning(\n            f\"Received un-modeled RTU message {msg.channel=} {msg.event=}\",\n            extra={\"rtu_channel\": msg.channel, \"rtu_event\": msg.event},\n        )\n\n    def register_rtu_event_callback(self, rtu_event: Type[RTUResponse], fn: Callable) -&gt; Callable:\n        \"\"\"\n        Register a callback that will be awaited whenever an RTU event is received that matches the\n        other arguments passed in (event, channel, channel_prefix, transaction_id).\n        \"\"\"\n\n        # When Sending/RTUManager receives and deserializes a message to an RTU event, it checks\n        # every registered callback. If those have a \"predicate_fn\", it runs that fn against the\n        # incoming message to decide whether to await the callback.\n        # The \"topic\" in the predicate_fn is always hardcoded to \"\" in the websocket backend, it's\n        # used in other backends like redis just not applicable here.\n        def predicate_fn(topic: Literal[\"\"], msg: RTUResponse):\n            return isinstance(msg, rtu_event)\n\n        return self.manager.register_callback(fn, on_predicate=predicate_fn)\n\n    def register_transaction_id_callback(self, transaction_id: uuid.UUID, fn: Callable):\n        \"\"\"\n        Register a callback that will be triggered whenever an RTU message comes in with a given\n        transaction id. Useful for doing things like waiting for a reply / event or error to be\n        propogated, e.g. for new delta requests.\n        \"\"\"\n\n        def predicate_fn(topic: Literal[\"\"], msg: RTUResponse):\n            return msg.transaction_id == transaction_id\n\n        return self.manager.register_callback(fn, on_predicate=predicate_fn)\n\n    def register_delta_callback(self, delta_class: Type[FileDelta], fn: Callable):\n        \"\"\"\n        Register a callback that may be triggered when we (eventually) apply an in-order Delta.\n\n        RTUClient has a separate mechanism for registering delta callbacks from the vanilla\n        Sending .register_callback flow because we don't necessarily want to run callbacks\n        immediately when we observe a Delta come over the RTU websocket. We may be dealing\n        with out-of-order deltas that are queued up and applied later on.\n\n        These callbacks are triggered by .apply_delta() and stored in a separate callback\n        list from vanilla Sending callbacks (manager.register_callback's)\n        \"\"\"\n        cb = DeltaCallback(delta_class=delta_class, fn=fn)\n        self.delta_callbacks.append(cb)\n        return cb\n\n    async def initialize(self, queue_size=0, inbound_workers=1, outbound_workers=1, poll_workers=1):\n        # see Sending base.py for details, calling .initialize starts asyncio.Tasks for\n        # - processing messages coming over the wire, dropping them onto inbound queue\n        # - taking messages taken off the inbound queue and running callbacks\n        # - taking messages from outbound queue and sending them over the wire\n        # - if queue_size is 0, it means no max queue size for inbound/outbound asyncio.Queue\n        await self.load_seed_notebook()\n        await self.manager.initialize(\n            queue_size=queue_size,\n            inbound_workers=inbound_workers,\n            outbound_workers=outbound_workers,\n            poll_workers=poll_workers,\n        )\n\n    async def shutdown(self, now: bool = False):\n        try:\n            await self.manager.shutdown(now=now)\n        except AttributeError:\n            # if the manager was never initialized, then the queues are None and will raise\n            # AttributeError while trying to .join() them\n            pass\n\n    async def load_seed_notebook(self):\n        \"\"\"\n        Pull in the seed notebook that will be the base document model of the NotebookBuilder, which\n        can then squash Deltas that update the Notebook, including deltas_to_apply on file subscribe\n        which represents changes that may have happened since the last \"save\" to s3.\n         - Get current file version and presigned url from /v1/files endpoint\n         - Download and parse seed notebook into Notebook / NotebookBuilder\n        \"\"\"\n        file: File = await self.api_client.get_file(file_id=self.file_id)\n\n        # Current file version id is used in file subscribe request\n        if not file.current_version_id:\n            logger.warning(f\"Gate shows no current version id for File {self.file_id}, aborting.\")\n            return await self.catastrophic_failure()\n        self.file_version_id = file.current_version_id\n\n        logger.info(\"Downloading seed Notebook\")\n        # Download seed Notebook and parse into Notebook / NotebookBuilder\n        # TODO: remove this hack if/when we get containers in Skaffold to be able to translate\n        # localhost urls to the minio pod/container -- relevant to Noteable devs only\n        if \"LOCAL_K8S\" in os.environ and bool(os.environ[\"LOCAL_K8S\"]):\n            file.presigned_download_url = file.presigned_download_url.replace(\"localhost\", \"minio\")\n        async with httpx.AsyncClient() as plain_http_client:\n            resp = await plain_http_client.get(file.presigned_download_url)\n            resp.raise_for_status()\n\n        seed_notebook = Notebook.model_validate(resp.json())\n        self.builder = NotebookBuilder(seed_notebook=seed_notebook)\n\n    # See Sending backends.websocket for details but a quick refresher on hook timing:\n    # - context_hook is called within the while True loop for inbound worker, outbound worker,\n    #   and poll_worker, it's for binding contextvars to every function call\n    # - connect_hook is called on websocket connect/reconnect, after resolving .unauth_ws future\n    # - auth_hook is called after connect_hook\n    # - init_hook is called after auth_hook\n    # - disconnect_hook is called when websocket disconnects, before reconnect attempt\n    # Re: *args / **kwargs in all hooks except context_hook below: Sending passes 'self' (mgr)\n    # as an arg to those, but we don't need to use it since we have self.manager to ref.\n    async def context_hook(self):\n        # In application code, might want to put structlog.bind_contextvars here\n        pass\n\n    async def connect_hook(self, *args, **kwargs):\n        ws: WebSocketClientProtocol = await self.manager.unauth_ws\n        self.rtu_session_id = ws.response_headers.get(\"rtu_session_id\")\n\n    async def disconnect_hook(self, *args, **kwargs):\n        self.rtu_session_id = None\n\n    async def auth_hook(self, *args, **kwargs):\n        \"\"\"\n        Called after the websocket connection is established. This also implicitly makes it so\n        .send() / ._publish will effectively suspend sending messages over the websocket\n        until we've observed an `authenticate_reply` event\n        \"\"\"\n        jwt = self.api_client.jwt\n        auth_request = AuthenticateRequest(\n            data={\"token\": jwt, \"rtu_client_type\": self.api_client.creator_client_type}\n        )\n\n        # auth_hook is the special situation that shouldn't use manager.send(),\n        # since that will ultimately delay sending things over the wire until\n        # we observe the auth reply. Instead use the unauth_ws directly and manually serialize\n        ws: WebSocketClientProtocol = await self.manager.unauth_ws\n        logger.info(f\"Sending auth request with jwt {jwt[:5]}...{jwt[-5:]}\")\n        await ws.send(auth_request.model_dump_json())\n\n    async def on_auth(self, msg: AuthenticateReply):\n        # hook for Application code to override, consider catastrophic failure on auth failure\n        if not msg.data.success:\n            logger.error(f\"Authentication failed: {msg.data}\")\n\n    async def _on_auth(self, msg: AuthenticateReply):\n        \"\"\"\n        Callback for event='authenticate_reply' on 'system' channel.\n\n        Application probably doesn't need to override this, override .on_auth instead which gets\n        awaited before this method sends out the file subscribe request.\n        \"\"\"\n        if msg.data.success:\n            logger.info(\"Authentication successful\")\n            self.user_id = msg.data.user.id\n            if self.manager.authed_ws.done():\n                # We've seen that sometimes on websocket reconnect, trying to .authed_ws.set_result\n                # throws an asyncio.InvalidStateError: Result is already set.\n                # Still a mystery how this happens, Sending websocket backend resets the authed_ws\n                # Future on websocket reconnect in a try / finally. If you figure it out, please\n                # create an issue or PR!\n                logger.warning(\"Authed websocket future already set, resetting to a new Future.\")\n                self.manager.authed_ws = asyncio.Future()\n\n            self.manager.authed_ws.set_result(self.manager.unauth_ws.result())\n            try:\n                await self.send_file_subscribe()\n            except Exception:\n                logger.exception(\"Error sending file subscribe request\")\n\n        await self.on_auth(msg)\n\n    async def send_file_subscribe(self):\n        \"\"\"\n        Once `authenticate_reply` is observed, we should send the File subscription request.\n        \"\"\"\n        # If our NotebookBuilder hasn't applied any deltas yet, then we should subscribe\n        # by the version_id. That is, we think we've pulled down a clean seed Notebook by\n        # s3 version id, and need to get deltas by the matching noteable version id.\n        #\n        # However if we've started applying deltas, such as after a Gate crash and RTU\n        # reconnect, then subscribe by the last applied delta id.\n        #\n        # Note this also means file subscribe won't happen until after we've pulled down\n        # the seed notebook from s3 for the first time, which is probably fine.\n        #\n        # Second note, subscribing by delta id all-0's throws an error in Gate.\n        if self.builder.last_applied_delta_id and self.builder.last_applied_delta_id != uuid.UUID(int=0):  # type: ignore # noqa: E501\n            logger.info(\n                \"Sending File subscribe request by last applied delta id\",\n                extra={\"from_delta_id\": str(self.builder.last_applied_delta_id)},\n            )\n            req_data = FileSubscribeRequestData(from_delta_id=self.builder.last_applied_delta_id)\n            req = FileSubscribeRequest(\n                channel=f\"files/{self.file_id}\",\n                data=req_data,\n            )\n\n        else:\n            logger.info(\n                \"Sending File subscribe request by version id\",\n                extra={\"from_version_id\": str(self.file_version_id)},\n            )\n            req_data = FileSubscribeRequestData(from_version_id=self.file_version_id)\n            req = FileSubscribeRequest(\n                channel=f\"files/{self.file_id}\",\n                data=req_data,\n            )\n\n        self.file_subscribe_timeout_task = asyncio.create_task(self.on_file_subscribe_timeout())\n        self.manager.send(req)\n\n    async def on_file_subscribe_timeout(self):\n        \"\"\"\n        Hook for Application code to override if we don't get the expected file subscribe reply\n        after some amount of seconds. Without a timeout, RTU Clients can easily get stuck forever\n        awaiting the .deltas_to_apply event that is resolved in file subscribe reply.\n        \"\"\"\n        await asyncio.sleep(self.file_subcribe_timeout)\n        logger.exception(\"File subscribe timeout reached\")\n        raise RuntimeError(\"File subscribe reply timeout\")\n\n    async def on_file_subscribe(self, msg: FileSubscribeReply):\n        # hook for Application code to override if it wants to do something special with\n        # file subscribe reply event on files/{self.file-id} channel\n        pass\n\n    async def _on_file_subscribe_reply(self, msg: FileSubscribeReply):\n        \"\"\"\n        Callback for event 'subscribe_reply' on 'files/{self.file-id}' channel\n\n        The file subscribe reply contains a bunch of information including which users are\n        subscribed to the Notebook (has it open in their browser), which Application code may care\n        about and want to handle in .on_file_subscribe.\n\n        Here the main concern is to handle \"deltas to apply\", which are any deltas that have been\n        created in between when our seed notebook version id was \"squashed\" and when we subscribed\n        to the file by version id / last delta id.\n        \"\"\"\n        # Kernel and cell states if there is a live Kernel\n        if msg.data.kernel_session:\n            self.kernel_state = msg.data.kernel_session.kernel.execution_state\n        if msg.data.cell_states:\n            self.cell_states = {item.cell_id: item.state for item in msg.data.cell_states}\n\n        # Go through \"Delta catchup\" and signal to ourselves that we can begin handling any new\n        # deltas coming in over the websocket. It's important not to start squashing incoming\n        # deltas until after we get the file subscribe and replay \"deltas to apply\" if there are any\n        for delta in msg.data.deltas_to_apply:\n            await self.queue_or_apply_delta(delta=delta)\n\n        self.deltas_to_apply_event.set()\n        # Prepare to replay any Deltas we received while waiting for file subscribe response.\n        # If we had deltas to apply, then Notebook Builder has a last applied delta id.\n        # If we did not, then we rely on Gate to have told us where the \"root\" of our deltas\n        # starts, so we don't apply deltas out of order at the start.\n        if not self.builder.last_applied_delta_id:\n            self.builder.last_applied_delta_id = msg.data.latest_delta_id\n        await self.replay_unapplied_deltas()\n\n        # Cancel the timeout task, should always exist but guarding against unexpected runtime err\n        if self.file_subscribe_timeout_task:\n            self.file_subscribe_timeout_task.cancel()\n\n        # Now all \"Delta catchup\" and \"inflight Deltas\" have been processed.\n        # Application code may want to do extra things like subscribe to kernels channel or users\n        # channel for each msg.data['user_subscriptions'].\n        await self.on_file_subscribe(msg)\n\n    async def file_unsubscribe(self):\n        \"\"\"\n        Send file unsubscribe request to Gate. This is called when the RTUClient is shutting down.\n        \"\"\"\n        req = FileUnsubscribeRequest(channel=f\"files/{self.file_id}\")\n        self.manager.send(req)\n\n    async def on_inconsistent_state_event(self, msg: InconsistentStateEvent):\n        \"\"\"\n        To \"reset\" our internal document model, we need to unsubscribe from the files channel at\n        the least, to stop getting new deltas in. Then we need to figure out what the new current\n        version id is, and pull down seed notebook, and then resubscribe to file channel.\n        \"\"\"\n        if self.inconsistent_state_event_count &gt;= 3:\n            logger.warning(\"Calling catastrophic failure after 3 inconsistent state events\")\n            return await self.catastrophic_failure()\n\n        logger.info(\"Received inconsistent state event, resetting NotebookBuilder\")\n        # There's the chance for some gnarly but rare edge cases here that would probably take a\n        # serious amount of thinking and logic to handle. Basically, what happens if new Deltas\n        # come in while we're trying to \"reset\" the document model after an inconsistent state?\n        # - Can the unsubscribe be handled in Gate after the second subscribe? Unlikely since it's\n        #   the same Gate handling both (websocket, sticky session).\n        # - Can Deltas end up coming in out of order, something come over the wire while we're\n        #   in the middle of resetting? Potentially, but that would just end up leading to failure\n        #   to apply delta and catastrophic failure, which is effectively what we were doing on\n        #   inconsistent_state_event before adding this method here.\n        await self.file_unsubscribe()\n        await self.load_seed_notebook()\n        await self.send_file_subscribe()\n        self.inconsistent_state_event_count += 1\n\n    async def _on_delta_recv(self, msg: NewDeltaEvent):\n        \"\"\"\n        Extract delta from GenericRTUReply and delegate to .queue_or_apply_delta\n        \"\"\"\n        # We may receive RTU / Delta events while we're still waiting to get a file_subscribe\n        # reply, which contains \"delta catchup\" which need to be applied before new deltas.\n        # We shot ourselves in the foot once by waiting for the deltas_to_apply_event in this method\n        # but that blocks handling any other received websocket/RTU messages. Instead, the right\n        # thing to do is probably add these to the unapplied_deltas list if we haven't done delta\n        # catchup yet.\n        if not self.deltas_to_apply_event.is_set():\n            self.unapplied_deltas.append(msg.data)\n        else:\n            await self.queue_or_apply_delta(delta=msg.data)\n\n    async def queue_or_apply_delta(self, delta: FileDelta):\n        \"\"\"\n        Checks whether we're able to apply the Delta by comparing its\n        parent_delta_id with the last_applied_delta_id in the NBBuilder.\n        If it is not a match, we may have received out of order deltas and we\n        queue it to be replayed later\n        \"\"\"\n        if self.builder.last_applied_delta_id is None:\n            # We need this for situations where we've downloaded the seed notebook and gotten deltas\n            # to apply from file subscribe reply, but do not have information about what the first\n            # delta in that deltas-to-apply list is.\n            await self.apply_delta(delta=delta)\n\n        elif delta.parent_delta_id == self.builder.last_applied_delta_id:\n            # For logging related to applying delta, override .pre_apply_delta\n            await self.apply_delta(delta=delta)\n            await self.replay_unapplied_deltas()\n\n        else:\n            # For logging related to queueing \"out of order\" Deltas, override .post_queue_delta\n            self.unapplied_deltas.append(delta)\n            await self.post_queue_delta(delta=delta)\n\n    async def post_queue_delta(self, delta: FileDelta):\n        \"\"\"\n        Hook for Application code to override if it wants to do something special when queueing\n        \"out of order\" Deltas.\n        \"\"\"\n        pass\n\n    async def pre_apply_delta(self, delta: FileDelta):\n        \"\"\"\n        Hook for Application code to override if it wants to do something special before running\n        \"squashing\" Delta into NotebookBuilder and running applicable callbacks.\n        \"\"\"\n        pass\n\n    async def failed_to_squash_delta(self, delta: FileDelta, exc: Exception):\n        \"\"\"\n        Hook for Application code to override when a Delta fails to \"squash\" into the in-memory\n        Notebook representation.\n        \"\"\"\n        pass\n\n    async def apply_delta(self, delta: FileDelta):\n        \"\"\"\n        Squash a Delta into the NotebookBuilder and run applicable callbacks\n\n         - If squashing a Delta into the in-memory Notebook representation fails for some reason,\n           then PA basically needs to crash because all follow on Delta application is very suspect\n           (e.g. future deltas think a cell exists when it doesn't, or content exists, etc)\n         - If callbacks are triggered, it is okay for them to fail and we just log it because those\n           are generally just side-effects, not core to applying future deltas\n\n        Note on alternative approach to handling delta squashing failures: @Seal suggested\n        redownloading Notebook and starting from latest delta rather than killing Kernel Pod but\n        we don't have great comm mechanisms for PA to tell Gate to squash the problematic Delta or\n        to figure out the most recent version in Cockroach / S3. For now, killing Kernel Pod on\n        NotebookBuilder apply and logging errors on side-effect callbacks is the best we can do.\n        \"\"\"\n        await self.pre_apply_delta(delta=delta)\n        try:\n            # \"squash\" delta into in-memory notebook representation\n            self.builder.apply_delta(delta)\n        except Exception as e:\n            await self.failed_to_squash_delta(delta=delta, exc=e)\n\n        # Run applicable callbacks concurrently, await all of them completing.\n        callbacks = []\n        for dc in self.delta_callbacks:\n            if isinstance(delta, dc.delta_class):\n                # Add coroutine to the callbacks list\n                callbacks.append(dc.fn(delta))\n\n        # Log errors on callbacks but don't stop RTU processing loop\n        results = await asyncio.gather(*callbacks, return_exceptions=True)\n        for callback, result in zip(callbacks, results):\n            if isinstance(result, Exception):\n                logger.error(\n                    \"Error trying to run callback while applying delta\",\n                    exc_info=\"\".join(traceback.format_tb(result.__traceback__)),\n                    extra={\n                        \"callback\": callback,\n                        \"delta\": delta,\n                        \"ename\": repr(result),\n                        \"traceback\": \"\".join(traceback.format_tb(result.__traceback__)),\n                    },\n                )\n\n    async def replay_unapplied_deltas(self):\n        \"\"\"\n        Attempt to apply any previous unapplied Deltas that were received out of order.\n        Calls itself recursively in case replaying unapplied deltas resulted in multiple\n        Deltas now being able to be applied. E.g. we received in order:\n         - {'id': 2, 'parent_id': 1} # applied because NBBuilder had no last_applied_delta_id\n         - {'id': 5, 'parent_id': 4} # queued because parent_id doesn't match builder\n         - {'id': 4, 'parent_id': 3} # queued because parent_id doesn't match builder\n         - {'id': 3, 'parent_id': 2} # applied, then needs to replay queued deltas\n\n        Replaying would make the third received delta be applied, which would let\n        replaying again also apply the second delta.\n        \"\"\"\n        for delta in self.unapplied_deltas:\n            if delta.parent_delta_id == self.builder.last_applied_delta_id:\n                logger.debug(\n                    \"Applying previously queued out of order delta\",\n                    extra={\"delta_id\": str(delta.id)},\n                )\n                await self.apply_delta(delta=delta)\n                self.unapplied_deltas.remove(delta)\n                return await self.replay_unapplied_deltas()\n\n    # Kernel and Cell states\n    async def on_kernel_status_update(self, msg: KernelStatusUpdateResponse):\n        \"\"\"Called when we receive a kernel_status_update_event on kernels/ channel\"\"\"\n        self.kernel_state = msg.data.kernel.execution_state\n        logger.debug(f\"updating Kernel state to: {self.kernel_state}\")\n\n    async def on_bulk_cell_state_update(self, msg: BulkCellStateUpdateResponse):\n        \"\"\"Called when we receive a bulk_cell_state_update_event on kernels/ channel\"\"\"\n        self.cell_states = {}\n        for item in msg.data.cell_states:\n            if item.cell_id in self._execute_cell_events:\n                # When we see that a cell we're monitoring has finished, resolve the Future to\n                # be the cell\n                if item.state in [\"finished_with_error\", \"finished_with_no_error\"]:\n                    logger.debug(\n                        \"Cell execution for monitored cell finished\",\n                        extra={\n                            \"cell_id\": item.cell_id,\n                            \"state\": item.state,\n                        },\n                    )\n                    fut = self._execute_cell_events[item.cell_id]\n                    if not fut.done():\n                        try:\n                            _, cell = self.builder.get_cell(item.cell_id)\n                            fut.set_result(cell)\n                        except CellNotFound:\n                            # This could happen if a cell was deleted in the middle of execution\n                            logger.warning(\n                                \"Cell execution finished for cell that doesn't exist in Notebook\",\n                                extra={\n                                    \"cell_id\": item.cell_id,\n                                    \"state\": item.state,\n                                },\n                            )\n                            fut.set_exception(CellNotFound(item.cell_id))\n            self.cell_states[item.cell_id] = item.state\n        logger.debug(\"Updated cell states\", extra={\"cell_states\": self.cell_states})\n\n    async def wait_for_kernel_idle(self):\n        \"\"\"Wait for the kernel to be idle\"\"\"\n        logger.debug(\"Waiting for Kernel to be idle\")\n        while self.kernel_state != \"idle\":\n            await asyncio.sleep(0.05)\n        logger.debug(\"Kernel is idle\")\n\n    async def new_delta_request(self, delta=FileDelta) -&gt; FileDelta:\n        \"\"\"\n        Send a new delta request to the server and wait for it to have been accepted and propogated\n        to other clients, as well as squashed into our own in-memory Notebook.\n        Raises errors if the Delta was rejected for any reason.\n        \"\"\"\n        req = DeltaRequestCallbackManager(client=self, delta=delta)\n        return await req.result\n\n    async def add_cell(\n        self,\n        source: str = \"\",\n        cell: Optional[NotebookCell] = None,\n        before_id: Optional[str] = None,\n        after_id: Optional[str] = None,\n    ) -&gt; NotebookCell:\n        \"\"\"\n        Adds a Cell to the Notebook.\n         - if a cell is passed in, will use that or otherwise make a CodeCell from source value\n         - If before_id and after_id are unspecified, then it will add the new cell at the bottom of\n            the notebook.\n        \"\"\"\n        if not cell:\n            cell = CodeCell(source=source)\n        # Default behavior: add cell to end of Notebook. Guard against a Notebook with no cells\n        if not before_id and not after_id and self.cell_ids:\n            after_id = self.cell_ids[-1]\n        props = NBCellsAddProperties(cell=cell, before_id=before_id, after_id=after_id, id=cell.id)\n        delta = NBCellsAdd(file_id=self.file_id, properties=props)\n        await self.new_delta_request(delta)\n        # grab newly-squashed cell\n        _, cell = self.builder.get_cell(cell.id)\n        return cell\n\n    async def delete_cell(self, cell_id: str) -&gt; NBCellsDelete:\n        delta = NBCellsDelete(file_id=self.file_id, properties={\"id\": cell_id})\n        return await self.new_delta_request(delta)\n\n    async def change_cell_type(\n        self,\n        cell_id: str,\n        cell_type: Literal[\"code\", \"markdown\", \"sql\"],\n        code_language: str = \"python\",\n        db_connection: str = \"@noteable\",\n        assign_results_to: Optional[str] = None,\n    ) -&gt; NotebookCell:\n        \"\"\"\n        Switch a cell between code, markdown, or SQL cell.\n         - code_language only relevant when switching to code cell\n         - db_connection and assign_results_to only relevant when switching to SQL cell\n        \"\"\"\n        self.builder.get_cell(cell_id)  # Raise CellNotFound if it doesn't exist\n        if cell_type == \"code\":\n            delta = CellMetadataReplace(\n                file_id=self.file_id,\n                resource_id=cell_id,\n                properties={\"language\": code_language, \"type\": \"code\"},\n            )\n            await self.new_delta_request(delta)\n        elif cell_type == \"markdown\":\n            delta = CellMetadataReplace(\n                file_id=self.file_id,\n                resource_id=cell_id,\n                properties={\"language\": \"markdown\", \"type\": \"markdown\"},\n            )\n            await self.new_delta_request(delta)\n        elif cell_type == \"sql\":\n            delta = CellMetadataReplace(\n                file_id=self.file_id,\n                resource_id=cell_id,\n                properties={\"language\": \"sql\", \"type\": \"code\"},\n            )\n            await self.new_delta_request(delta)\n\n            if not assign_results_to:\n                name_suffix = \"\".join(random.choices(string.ascii_lowercase, k=4))\n                assign_results_to = \"df_\" + name_suffix\n            delta = CellMetadataUpdate(\n                file_id=self.file_id,\n                resource_id=cell_id,\n                properties={\n                    \"path\": [\"metadata\", \"noteable\"],\n                    \"value\": {\n                        \"cell_type\": \"sql\",\n                        \"db_connection\": db_connection,\n                        \"assign_results_to\": assign_results_to,\n                    },\n                },\n            )\n            await self.new_delta_request(delta)\n        else:\n            raise ValueError(f\"Unknown cell type {cell_type}\")\n        # Grab updated cell post-squashing\n        _, cell = self.builder.get_cell(cell_id)\n        return cell\n\n    async def update_cell_content(self, cell_id: str, patch: str) -&gt; NotebookCell:\n        \"\"\"\n        Update cell content with a diff-match-patch patch string\n        \"\"\"\n        delta = CellContentsUpdate(\n            file_id=self.file_id, resource_id=cell_id, properties={\"patch\": patch}\n        )\n        await self.new_delta_request(delta)\n        # Grab updated cell post-squashing\n        _, cell = self.builder.get_cell(cell_id)\n        return cell\n\n    async def replace_cell_content(self, cell_id: str, source: str) -&gt; NotebookCell:\n        \"\"\"\n        Replace cell content with a string\n        \"\"\"\n        delta = CellContentsReplace(\n            file_id=self.file_id, resource_id=cell_id, properties={\"source\": source}\n        )\n        await self.new_delta_request(delta)\n        # Grab updated cell post-squashing\n        _, cell = self.builder.get_cell(cell_id)\n        return cell\n\n    async def queue_execution(\n        self,\n        cell_id: Optional[str] = None,\n        before_id: Optional[str] = None,\n        after_id: Optional[str] = None,\n        run_all: bool = False,\n    ) -&gt; Dict[asyncio.Future[CodeCell], str]:\n        \"\"\"\n        Execute an individual cell or multiple cells in the Notebook. The return value is a dict of\n        {future: cell_id}, even in the case of executing a single cell.\n\n         - Only code Cells can be executed. When running multiple cells with before / after / all\n           non-code cells will be excluded automatically\n         - Code cells with no source are not executed on Noteable backend, so they'll be skipped\n         - Outputs should be available from the cell.output_collection_id property\n\n        Use:\n        queued_execute = await rtu_client.queue_execution(run_all=True)\n        done, pending = await asyncio.wait(*queued_execute, timeout=5)\n\n        still_running_cell_ids = [queued_execute[f] for f in pending]\n        \"\"\"\n        if not cell_id and not before_id and not after_id and not run_all:\n            raise ValueError(\"One of cell_id, before_id, after_id, or run_all must be set.\")\n        if self.kernel_state == \"not_started\":\n            raise RuntimeError(\n                \"Cannot submit cell execution requests for Notebook that has not started a Kernel. Use api_client.launch_kernel to start one.\"  # noqa: E501\n            )\n\n        if cell_id:\n            cell_ids = [cell_id]\n            delta = CellExecute(file_id=self.file_id, resource_id=cell_id)\n        elif before_id:\n            idx, cell = self.builder.get_cell(before_id)  # can raise CellNotFound\n            cell_ids = self.cell_ids[: idx + 1]  # inclusive of the \"before_id\" cell\n            delta = CellExecuteBefore(file_id=self.file_id, resource_id=before_id)\n        elif after_id:\n            idx, cell = self.builder.get_cell(after_id)  # can raise CellNotFound\n            cell_ids = self.cell_ids[idx:]  # inclusive of the \"after_id\" cell\n            delta = CellExecuteAfter(file_id=self.file_id, resource_id=after_id)\n        else:\n            cell_ids = self.cell_ids[:]\n            delta = CellExecuteAll(file_id=self.file_id)\n        futures = {}\n        for cell_id in cell_ids:\n            # Only create futures for Code cells that have something in source. Otherwise the cell\n            # will never get executed by PA/Kernel, so we'd never see cell status and resolve future\n            future = asyncio.Future()\n            idx, cell = self.builder.get_cell(cell_id)\n            if cell.cell_type == \"code\" and cell.source.strip():\n                self._execute_cell_events[cell_id] = future\n                futures[future] = cell_id\n        await self.new_delta_request(delta)\n        return futures\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.cell_ids","title":"<code>cell_ids</code>  <code>property</code>","text":"<p>Return list of cell_id's in order from NotebookBuilder in-memory model</p>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.kernel_pod_name","title":"<code>kernel_pod_name: str</code>  <code>property</code>","text":"<p>Transform the file_id into the Pod name used to build the kernels/ RTU channel</p>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.__init__","title":"<code>__init__(api_client, file_id, file_subscribe_timeout=10)</code>","text":"<p>High-level client over the Sending websocket backend / RTUManager (serialize websocket msgs to/from RTU models) that allows you to add callbacks by RTU event type or Delta type/action.</p> <ul> <li>On .initialize(), will make a websocket connection to Gate</li> <li>RTUManager / Sending websocket backend handles reconnection</li> <li>RTUClient sets .manager.auth_hook to kick off the auth request, don't override that</li> <li> <p>awaits .on_websocket_connect() hook that you can override in application code</p> </li> <li> <p>After websocket connection is established, sends authenticate_request on system channel</p> </li> <li> <p>Has a callback registered for 'authenticate_reply' on system channel which will     await .on_auth (hook to define in application code) then send file subscribe request</p> </li> <li> <p>After authentication, sends subscribe_request to files/{file_id} channel</p> </li> <li> <p>awaits .on_file_subscribe() hook that you can override in application code</p> </li> <li> <p>Use .register_rtu_event_callback to register callbacks that are run against RTU messages</p> </li> <li> <p>Use .register_delta_callback to register callbacks that are run against Deltas</p> </li> <li>May not run when message is initially received if the Delta is \"out of order\", RTUClient     handles queueing and replaying out of order deltas</li> <li>Callbacks run after the Delta is \"squashed\" into {builder}</li> </ul> Source code in <code>origami/clients/rtu.py</code> <pre><code>def __init__(\n    self,\n    api_client: APIClient,\n    file_id: uuid.UUID,\n    file_subscribe_timeout: int = 10,\n):\n    \"\"\"\n    High-level client over the Sending websocket backend / RTUManager (serialize websocket msgs\n    to/from RTU models) that allows you to add callbacks by RTU event type or Delta type/action.\n\n    - On .initialize(), will make a websocket connection to Gate\n      - RTUManager / Sending websocket backend handles reconnection\n      - RTUClient sets .manager.auth_hook to kick off the auth request, don't override that\n      - awaits .on_websocket_connect() hook that you can override in application code\n\n    - After websocket connection is established, sends authenticate_request on system channel\n      - Has a callback registered for 'authenticate_reply' on system channel which will\n        await .on_auth (hook to define in application code) then send file subscribe request\n\n    - After authentication, sends subscribe_request to files/{file_id} channel\n      - awaits .on_file_subscribe() hook that you can override in application code\n\n    - Use .register_rtu_event_callback to register callbacks that are run against RTU messages\n\n    - Use .register_delta_callback to register callbacks that are run against Deltas\n      - May not run when message is initially received if the Delta is \"out of order\", RTUClient\n        handles queueing and replaying out of order deltas\n      - Callbacks run after the Delta is \"squashed\" into {builder}\n    \"\"\"\n    self.api_client = api_client\n\n    rtu_url = (\n        os.environ.get(\"NOTEABLE_RTU_URL\")\n        or api_client.api_base_url.replace(\"http\", \"ws\") + \"/v1/rtu\"\n    )\n    self.manager = RTUManager(ws_url=rtu_url)  # Sending websocket backend w/ RTU serialization\n    self.file_id = file_id\n\n    self.rtu_session_id = None  # Set after establishing websocket connection on .initialize()\n    self.builder = None  # Set from .build_notebook, called as part of .initialize()\n    self.user_id = None  # set during authenticate_reply handling, used in new_delta_request\n\n    # When we send file subscribe request, it'll create a task to run .on_file_subscribe_timeout\n    # which should blow up the RTU Client. Otherwise we can get stuck indefinitely waiting\n    # for .deltas_to_apply event. If we get through initialization okay, the task will cancel\n    self.file_subcribe_timeout = file_subscribe_timeout\n    self.file_subscribe_timeout_task: Optional[asyncio.Task] = None\n\n    # Callbacks triggered from Sending based on websocket connection lifecycle events\n    self.manager.auth_hook = self.auth_hook\n    self.manager.connect_hook = self.connect_hook\n    self.manager.context_hook = self.context_hook\n    self.manager.disconnect_hook = self.disconnect_hook\n\n    # Callbacks that are part of the startup flow (auth and File subscribe)\n    self.register_rtu_event_callback(rtu_event=AuthenticateReply, fn=self._on_auth)\n    self.register_rtu_event_callback(\n        rtu_event=FileSubscribeReply, fn=self._on_file_subscribe_reply\n    )\n\n    # Incoming Delta handling. Key points here are:\n    # - we don't want to squash deltas until we get file subscribe reply and deltas-to-apply\n    # - Deltas may be \"out of order\", should save to be replayed later\n    # - When finally applying Delta \"in order\", then we await callbacks by delta type/action\n    # See self.new_delta_request for more details on sending out Deltas\n    self.delta_callbacks: List[DeltaCallback] = []\n    self.unapplied_deltas: List[FileDelta] = []  # \"out of order deltas\" to be replayed\n    self.deltas_to_apply_event = asyncio.Event()  # set in ._on_file_subscribe_reply\n\n    self.register_rtu_event_callback(rtu_event=NewDeltaEvent, fn=self._on_delta_recv)\n\n    # Kernel and cell state handling\n    self.kernel_state: str = \"not_started\"  # value used when there's no Kernel for a Notebook\n    self.cell_states: Dict[str, str] = {}\n\n    self.register_rtu_event_callback(\n        rtu_event=KernelStatusUpdateResponse, fn=self.on_kernel_status_update\n    )\n    self.register_rtu_event_callback(\n        rtu_event=BulkCellStateUpdateResponse, fn=self.on_bulk_cell_state_update\n    )\n\n    # An inconsistent state event means the Notebook was updated in a way that \"broke\" Delta\n    # history, and the RTUClient needs to pull in the seed notebook and re-apply deltas from\n    # a \"new\" current version id in order to catch up\n    #\n    # However if we get several inconsistent state events (say from getting them on file\n    # resubscribe), we'll call catastrophic_failure to let the application handle tear-down\n    self.inconsistent_state_event_count = 0\n    self.register_rtu_event_callback(\n        rtu_event=InconsistentStateEvent, fn=self.on_inconsistent_state_event\n    )\n\n    # Log anytime we get an un-modeled RTU message.\n    # Not going through register_rtu_event_callback because isinstance would catch child classes\n    def predicate_fn(topic: Literal[\"\"], msg: RTUResponse):\n        return type(msg) == BaseRTUResponse\n\n    self.manager.register_callback(self._on_unmodeled_rtu_msg, on_predicate=predicate_fn)\n\n    # When someone calls .execute_cell, return an asyncio.Future that will be resolved to be\n    # the updated Cell model when the cell is done executing\n    self._execute_cell_events: Dict[str, asyncio.Future[CodeCell]] = {}\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.add_cell","title":"<code>add_cell(source='', cell=None, before_id=None, after_id=None)</code>  <code>async</code>","text":"<p>Adds a Cell to the Notebook.  - if a cell is passed in, will use that or otherwise make a CodeCell from source value  - If before_id and after_id are unspecified, then it will add the new cell at the bottom of     the notebook.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def add_cell(\n    self,\n    source: str = \"\",\n    cell: Optional[NotebookCell] = None,\n    before_id: Optional[str] = None,\n    after_id: Optional[str] = None,\n) -&gt; NotebookCell:\n    \"\"\"\n    Adds a Cell to the Notebook.\n     - if a cell is passed in, will use that or otherwise make a CodeCell from source value\n     - If before_id and after_id are unspecified, then it will add the new cell at the bottom of\n        the notebook.\n    \"\"\"\n    if not cell:\n        cell = CodeCell(source=source)\n    # Default behavior: add cell to end of Notebook. Guard against a Notebook with no cells\n    if not before_id and not after_id and self.cell_ids:\n        after_id = self.cell_ids[-1]\n    props = NBCellsAddProperties(cell=cell, before_id=before_id, after_id=after_id, id=cell.id)\n    delta = NBCellsAdd(file_id=self.file_id, properties=props)\n    await self.new_delta_request(delta)\n    # grab newly-squashed cell\n    _, cell = self.builder.get_cell(cell.id)\n    return cell\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.apply_delta","title":"<code>apply_delta(delta)</code>  <code>async</code>","text":"<p>Squash a Delta into the NotebookBuilder and run applicable callbacks</p> <ul> <li>If squashing a Delta into the in-memory Notebook representation fails for some reason,    then PA basically needs to crash because all follow on Delta application is very suspect    (e.g. future deltas think a cell exists when it doesn't, or content exists, etc)</li> <li>If callbacks are triggered, it is okay for them to fail and we just log it because those    are generally just side-effects, not core to applying future deltas</li> </ul> <p>Note on alternative approach to handling delta squashing failures: @Seal suggested redownloading Notebook and starting from latest delta rather than killing Kernel Pod but we don't have great comm mechanisms for PA to tell Gate to squash the problematic Delta or to figure out the most recent version in Cockroach / S3. For now, killing Kernel Pod on NotebookBuilder apply and logging errors on side-effect callbacks is the best we can do.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def apply_delta(self, delta: FileDelta):\n    \"\"\"\n    Squash a Delta into the NotebookBuilder and run applicable callbacks\n\n     - If squashing a Delta into the in-memory Notebook representation fails for some reason,\n       then PA basically needs to crash because all follow on Delta application is very suspect\n       (e.g. future deltas think a cell exists when it doesn't, or content exists, etc)\n     - If callbacks are triggered, it is okay for them to fail and we just log it because those\n       are generally just side-effects, not core to applying future deltas\n\n    Note on alternative approach to handling delta squashing failures: @Seal suggested\n    redownloading Notebook and starting from latest delta rather than killing Kernel Pod but\n    we don't have great comm mechanisms for PA to tell Gate to squash the problematic Delta or\n    to figure out the most recent version in Cockroach / S3. For now, killing Kernel Pod on\n    NotebookBuilder apply and logging errors on side-effect callbacks is the best we can do.\n    \"\"\"\n    await self.pre_apply_delta(delta=delta)\n    try:\n        # \"squash\" delta into in-memory notebook representation\n        self.builder.apply_delta(delta)\n    except Exception as e:\n        await self.failed_to_squash_delta(delta=delta, exc=e)\n\n    # Run applicable callbacks concurrently, await all of them completing.\n    callbacks = []\n    for dc in self.delta_callbacks:\n        if isinstance(delta, dc.delta_class):\n            # Add coroutine to the callbacks list\n            callbacks.append(dc.fn(delta))\n\n    # Log errors on callbacks but don't stop RTU processing loop\n    results = await asyncio.gather(*callbacks, return_exceptions=True)\n    for callback, result in zip(callbacks, results):\n        if isinstance(result, Exception):\n            logger.error(\n                \"Error trying to run callback while applying delta\",\n                exc_info=\"\".join(traceback.format_tb(result.__traceback__)),\n                extra={\n                    \"callback\": callback,\n                    \"delta\": delta,\n                    \"ename\": repr(result),\n                    \"traceback\": \"\".join(traceback.format_tb(result.__traceback__)),\n                },\n            )\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.auth_hook","title":"<code>auth_hook(*args, **kwargs)</code>  <code>async</code>","text":"<p>Called after the websocket connection is established. This also implicitly makes it so .send() / ._publish will effectively suspend sending messages over the websocket until we've observed an <code>authenticate_reply</code> event</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def auth_hook(self, *args, **kwargs):\n    \"\"\"\n    Called after the websocket connection is established. This also implicitly makes it so\n    .send() / ._publish will effectively suspend sending messages over the websocket\n    until we've observed an `authenticate_reply` event\n    \"\"\"\n    jwt = self.api_client.jwt\n    auth_request = AuthenticateRequest(\n        data={\"token\": jwt, \"rtu_client_type\": self.api_client.creator_client_type}\n    )\n\n    # auth_hook is the special situation that shouldn't use manager.send(),\n    # since that will ultimately delay sending things over the wire until\n    # we observe the auth reply. Instead use the unauth_ws directly and manually serialize\n    ws: WebSocketClientProtocol = await self.manager.unauth_ws\n    logger.info(f\"Sending auth request with jwt {jwt[:5]}...{jwt[-5:]}\")\n    await ws.send(auth_request.model_dump_json())\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.catastrophic_failure","title":"<code>catastrophic_failure()</code>  <code>async</code>","text":"<p>A hook for applications like PA to override so they can handle things like Pod shutdown in cases where the RTUClient cannot recover. Examples are when reloading Notebook state after inconsistent_state_event and not getting a current_version_id to subscribe by or getting Deltas that cannot be squashed into the builder</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def catastrophic_failure(self):\n    \"\"\"\n    A hook for applications like PA to override so they can handle things like Pod shutdown\n    in cases where the RTUClient cannot recover. Examples are when reloading Notebook state\n    after inconsistent_state_event and not getting a current_version_id to subscribe by or\n    getting Deltas that cannot be squashed into the builder\n    \"\"\"\n    logger.warning(\"Catastrophic failure, RTU applications can override this hook\")\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.change_cell_type","title":"<code>change_cell_type(cell_id, cell_type, code_language='python', db_connection='@noteable', assign_results_to=None)</code>  <code>async</code>","text":"<p>Switch a cell between code, markdown, or SQL cell.  - code_language only relevant when switching to code cell  - db_connection and assign_results_to only relevant when switching to SQL cell</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def change_cell_type(\n    self,\n    cell_id: str,\n    cell_type: Literal[\"code\", \"markdown\", \"sql\"],\n    code_language: str = \"python\",\n    db_connection: str = \"@noteable\",\n    assign_results_to: Optional[str] = None,\n) -&gt; NotebookCell:\n    \"\"\"\n    Switch a cell between code, markdown, or SQL cell.\n     - code_language only relevant when switching to code cell\n     - db_connection and assign_results_to only relevant when switching to SQL cell\n    \"\"\"\n    self.builder.get_cell(cell_id)  # Raise CellNotFound if it doesn't exist\n    if cell_type == \"code\":\n        delta = CellMetadataReplace(\n            file_id=self.file_id,\n            resource_id=cell_id,\n            properties={\"language\": code_language, \"type\": \"code\"},\n        )\n        await self.new_delta_request(delta)\n    elif cell_type == \"markdown\":\n        delta = CellMetadataReplace(\n            file_id=self.file_id,\n            resource_id=cell_id,\n            properties={\"language\": \"markdown\", \"type\": \"markdown\"},\n        )\n        await self.new_delta_request(delta)\n    elif cell_type == \"sql\":\n        delta = CellMetadataReplace(\n            file_id=self.file_id,\n            resource_id=cell_id,\n            properties={\"language\": \"sql\", \"type\": \"code\"},\n        )\n        await self.new_delta_request(delta)\n\n        if not assign_results_to:\n            name_suffix = \"\".join(random.choices(string.ascii_lowercase, k=4))\n            assign_results_to = \"df_\" + name_suffix\n        delta = CellMetadataUpdate(\n            file_id=self.file_id,\n            resource_id=cell_id,\n            properties={\n                \"path\": [\"metadata\", \"noteable\"],\n                \"value\": {\n                    \"cell_type\": \"sql\",\n                    \"db_connection\": db_connection,\n                    \"assign_results_to\": assign_results_to,\n                },\n            },\n        )\n        await self.new_delta_request(delta)\n    else:\n        raise ValueError(f\"Unknown cell type {cell_type}\")\n    # Grab updated cell post-squashing\n    _, cell = self.builder.get_cell(cell_id)\n    return cell\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.failed_to_squash_delta","title":"<code>failed_to_squash_delta(delta, exc)</code>  <code>async</code>","text":"<p>Hook for Application code to override when a Delta fails to \"squash\" into the in-memory Notebook representation.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def failed_to_squash_delta(self, delta: FileDelta, exc: Exception):\n    \"\"\"\n    Hook for Application code to override when a Delta fails to \"squash\" into the in-memory\n    Notebook representation.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.file_unsubscribe","title":"<code>file_unsubscribe()</code>  <code>async</code>","text":"<p>Send file unsubscribe request to Gate. This is called when the RTUClient is shutting down.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def file_unsubscribe(self):\n    \"\"\"\n    Send file unsubscribe request to Gate. This is called when the RTUClient is shutting down.\n    \"\"\"\n    req = FileUnsubscribeRequest(channel=f\"files/{self.file_id}\")\n    self.manager.send(req)\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.load_seed_notebook","title":"<code>load_seed_notebook()</code>  <code>async</code>","text":"<p>Pull in the seed notebook that will be the base document model of the NotebookBuilder, which can then squash Deltas that update the Notebook, including deltas_to_apply on file subscribe which represents changes that may have happened since the last \"save\" to s3.  - Get current file version and presigned url from /v1/files endpoint  - Download and parse seed notebook into Notebook / NotebookBuilder</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def load_seed_notebook(self):\n    \"\"\"\n    Pull in the seed notebook that will be the base document model of the NotebookBuilder, which\n    can then squash Deltas that update the Notebook, including deltas_to_apply on file subscribe\n    which represents changes that may have happened since the last \"save\" to s3.\n     - Get current file version and presigned url from /v1/files endpoint\n     - Download and parse seed notebook into Notebook / NotebookBuilder\n    \"\"\"\n    file: File = await self.api_client.get_file(file_id=self.file_id)\n\n    # Current file version id is used in file subscribe request\n    if not file.current_version_id:\n        logger.warning(f\"Gate shows no current version id for File {self.file_id}, aborting.\")\n        return await self.catastrophic_failure()\n    self.file_version_id = file.current_version_id\n\n    logger.info(\"Downloading seed Notebook\")\n    # Download seed Notebook and parse into Notebook / NotebookBuilder\n    # TODO: remove this hack if/when we get containers in Skaffold to be able to translate\n    # localhost urls to the minio pod/container -- relevant to Noteable devs only\n    if \"LOCAL_K8S\" in os.environ and bool(os.environ[\"LOCAL_K8S\"]):\n        file.presigned_download_url = file.presigned_download_url.replace(\"localhost\", \"minio\")\n    async with httpx.AsyncClient() as plain_http_client:\n        resp = await plain_http_client.get(file.presigned_download_url)\n        resp.raise_for_status()\n\n    seed_notebook = Notebook.model_validate(resp.json())\n    self.builder = NotebookBuilder(seed_notebook=seed_notebook)\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.new_delta_request","title":"<code>new_delta_request(delta=FileDelta)</code>  <code>async</code>","text":"<p>Send a new delta request to the server and wait for it to have been accepted and propogated to other clients, as well as squashed into our own in-memory Notebook. Raises errors if the Delta was rejected for any reason.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def new_delta_request(self, delta=FileDelta) -&gt; FileDelta:\n    \"\"\"\n    Send a new delta request to the server and wait for it to have been accepted and propogated\n    to other clients, as well as squashed into our own in-memory Notebook.\n    Raises errors if the Delta was rejected for any reason.\n    \"\"\"\n    req = DeltaRequestCallbackManager(client=self, delta=delta)\n    return await req.result\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.on_bulk_cell_state_update","title":"<code>on_bulk_cell_state_update(msg)</code>  <code>async</code>","text":"<p>Called when we receive a bulk_cell_state_update_event on kernels/ channel</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def on_bulk_cell_state_update(self, msg: BulkCellStateUpdateResponse):\n    \"\"\"Called when we receive a bulk_cell_state_update_event on kernels/ channel\"\"\"\n    self.cell_states = {}\n    for item in msg.data.cell_states:\n        if item.cell_id in self._execute_cell_events:\n            # When we see that a cell we're monitoring has finished, resolve the Future to\n            # be the cell\n            if item.state in [\"finished_with_error\", \"finished_with_no_error\"]:\n                logger.debug(\n                    \"Cell execution for monitored cell finished\",\n                    extra={\n                        \"cell_id\": item.cell_id,\n                        \"state\": item.state,\n                    },\n                )\n                fut = self._execute_cell_events[item.cell_id]\n                if not fut.done():\n                    try:\n                        _, cell = self.builder.get_cell(item.cell_id)\n                        fut.set_result(cell)\n                    except CellNotFound:\n                        # This could happen if a cell was deleted in the middle of execution\n                        logger.warning(\n                            \"Cell execution finished for cell that doesn't exist in Notebook\",\n                            extra={\n                                \"cell_id\": item.cell_id,\n                                \"state\": item.state,\n                            },\n                        )\n                        fut.set_exception(CellNotFound(item.cell_id))\n        self.cell_states[item.cell_id] = item.state\n    logger.debug(\"Updated cell states\", extra={\"cell_states\": self.cell_states})\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.on_file_subscribe_timeout","title":"<code>on_file_subscribe_timeout()</code>  <code>async</code>","text":"<p>Hook for Application code to override if we don't get the expected file subscribe reply after some amount of seconds. Without a timeout, RTU Clients can easily get stuck forever awaiting the .deltas_to_apply event that is resolved in file subscribe reply.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def on_file_subscribe_timeout(self):\n    \"\"\"\n    Hook for Application code to override if we don't get the expected file subscribe reply\n    after some amount of seconds. Without a timeout, RTU Clients can easily get stuck forever\n    awaiting the .deltas_to_apply event that is resolved in file subscribe reply.\n    \"\"\"\n    await asyncio.sleep(self.file_subcribe_timeout)\n    logger.exception(\"File subscribe timeout reached\")\n    raise RuntimeError(\"File subscribe reply timeout\")\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.on_inconsistent_state_event","title":"<code>on_inconsistent_state_event(msg)</code>  <code>async</code>","text":"<p>To \"reset\" our internal document model, we need to unsubscribe from the files channel at the least, to stop getting new deltas in. Then we need to figure out what the new current version id is, and pull down seed notebook, and then resubscribe to file channel.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def on_inconsistent_state_event(self, msg: InconsistentStateEvent):\n    \"\"\"\n    To \"reset\" our internal document model, we need to unsubscribe from the files channel at\n    the least, to stop getting new deltas in. Then we need to figure out what the new current\n    version id is, and pull down seed notebook, and then resubscribe to file channel.\n    \"\"\"\n    if self.inconsistent_state_event_count &gt;= 3:\n        logger.warning(\"Calling catastrophic failure after 3 inconsistent state events\")\n        return await self.catastrophic_failure()\n\n    logger.info(\"Received inconsistent state event, resetting NotebookBuilder\")\n    # There's the chance for some gnarly but rare edge cases here that would probably take a\n    # serious amount of thinking and logic to handle. Basically, what happens if new Deltas\n    # come in while we're trying to \"reset\" the document model after an inconsistent state?\n    # - Can the unsubscribe be handled in Gate after the second subscribe? Unlikely since it's\n    #   the same Gate handling both (websocket, sticky session).\n    # - Can Deltas end up coming in out of order, something come over the wire while we're\n    #   in the middle of resetting? Potentially, but that would just end up leading to failure\n    #   to apply delta and catastrophic failure, which is effectively what we were doing on\n    #   inconsistent_state_event before adding this method here.\n    await self.file_unsubscribe()\n    await self.load_seed_notebook()\n    await self.send_file_subscribe()\n    self.inconsistent_state_event_count += 1\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.on_kernel_status_update","title":"<code>on_kernel_status_update(msg)</code>  <code>async</code>","text":"<p>Called when we receive a kernel_status_update_event on kernels/ channel</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def on_kernel_status_update(self, msg: KernelStatusUpdateResponse):\n    \"\"\"Called when we receive a kernel_status_update_event on kernels/ channel\"\"\"\n    self.kernel_state = msg.data.kernel.execution_state\n    logger.debug(f\"updating Kernel state to: {self.kernel_state}\")\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.post_queue_delta","title":"<code>post_queue_delta(delta)</code>  <code>async</code>","text":"<p>Hook for Application code to override if it wants to do something special when queueing \"out of order\" Deltas.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def post_queue_delta(self, delta: FileDelta):\n    \"\"\"\n    Hook for Application code to override if it wants to do something special when queueing\n    \"out of order\" Deltas.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.pre_apply_delta","title":"<code>pre_apply_delta(delta)</code>  <code>async</code>","text":"<p>Hook for Application code to override if it wants to do something special before running \"squashing\" Delta into NotebookBuilder and running applicable callbacks.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def pre_apply_delta(self, delta: FileDelta):\n    \"\"\"\n    Hook for Application code to override if it wants to do something special before running\n    \"squashing\" Delta into NotebookBuilder and running applicable callbacks.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.queue_execution","title":"<code>queue_execution(cell_id=None, before_id=None, after_id=None, run_all=False)</code>  <code>async</code>","text":"<p>Execute an individual cell or multiple cells in the Notebook. The return value is a dict of {future: cell_id}, even in the case of executing a single cell.</p> <ul> <li>Only code Cells can be executed. When running multiple cells with before / after / all    non-code cells will be excluded automatically</li> <li>Code cells with no source are not executed on Noteable backend, so they'll be skipped</li> <li>Outputs should be available from the cell.output_collection_id property</li> </ul> <p>Use: queued_execute = await rtu_client.queue_execution(run_all=True) done, pending = await asyncio.wait(*queued_execute, timeout=5)</p> <p>still_running_cell_ids = [queued_execute[f] for f in pending]</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def queue_execution(\n    self,\n    cell_id: Optional[str] = None,\n    before_id: Optional[str] = None,\n    after_id: Optional[str] = None,\n    run_all: bool = False,\n) -&gt; Dict[asyncio.Future[CodeCell], str]:\n    \"\"\"\n    Execute an individual cell or multiple cells in the Notebook. The return value is a dict of\n    {future: cell_id}, even in the case of executing a single cell.\n\n     - Only code Cells can be executed. When running multiple cells with before / after / all\n       non-code cells will be excluded automatically\n     - Code cells with no source are not executed on Noteable backend, so they'll be skipped\n     - Outputs should be available from the cell.output_collection_id property\n\n    Use:\n    queued_execute = await rtu_client.queue_execution(run_all=True)\n    done, pending = await asyncio.wait(*queued_execute, timeout=5)\n\n    still_running_cell_ids = [queued_execute[f] for f in pending]\n    \"\"\"\n    if not cell_id and not before_id and not after_id and not run_all:\n        raise ValueError(\"One of cell_id, before_id, after_id, or run_all must be set.\")\n    if self.kernel_state == \"not_started\":\n        raise RuntimeError(\n            \"Cannot submit cell execution requests for Notebook that has not started a Kernel. Use api_client.launch_kernel to start one.\"  # noqa: E501\n        )\n\n    if cell_id:\n        cell_ids = [cell_id]\n        delta = CellExecute(file_id=self.file_id, resource_id=cell_id)\n    elif before_id:\n        idx, cell = self.builder.get_cell(before_id)  # can raise CellNotFound\n        cell_ids = self.cell_ids[: idx + 1]  # inclusive of the \"before_id\" cell\n        delta = CellExecuteBefore(file_id=self.file_id, resource_id=before_id)\n    elif after_id:\n        idx, cell = self.builder.get_cell(after_id)  # can raise CellNotFound\n        cell_ids = self.cell_ids[idx:]  # inclusive of the \"after_id\" cell\n        delta = CellExecuteAfter(file_id=self.file_id, resource_id=after_id)\n    else:\n        cell_ids = self.cell_ids[:]\n        delta = CellExecuteAll(file_id=self.file_id)\n    futures = {}\n    for cell_id in cell_ids:\n        # Only create futures for Code cells that have something in source. Otherwise the cell\n        # will never get executed by PA/Kernel, so we'd never see cell status and resolve future\n        future = asyncio.Future()\n        idx, cell = self.builder.get_cell(cell_id)\n        if cell.cell_type == \"code\" and cell.source.strip():\n            self._execute_cell_events[cell_id] = future\n            futures[future] = cell_id\n    await self.new_delta_request(delta)\n    return futures\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.queue_or_apply_delta","title":"<code>queue_or_apply_delta(delta)</code>  <code>async</code>","text":"<p>Checks whether we're able to apply the Delta by comparing its parent_delta_id with the last_applied_delta_id in the NBBuilder. If it is not a match, we may have received out of order deltas and we queue it to be replayed later</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def queue_or_apply_delta(self, delta: FileDelta):\n    \"\"\"\n    Checks whether we're able to apply the Delta by comparing its\n    parent_delta_id with the last_applied_delta_id in the NBBuilder.\n    If it is not a match, we may have received out of order deltas and we\n    queue it to be replayed later\n    \"\"\"\n    if self.builder.last_applied_delta_id is None:\n        # We need this for situations where we've downloaded the seed notebook and gotten deltas\n        # to apply from file subscribe reply, but do not have information about what the first\n        # delta in that deltas-to-apply list is.\n        await self.apply_delta(delta=delta)\n\n    elif delta.parent_delta_id == self.builder.last_applied_delta_id:\n        # For logging related to applying delta, override .pre_apply_delta\n        await self.apply_delta(delta=delta)\n        await self.replay_unapplied_deltas()\n\n    else:\n        # For logging related to queueing \"out of order\" Deltas, override .post_queue_delta\n        self.unapplied_deltas.append(delta)\n        await self.post_queue_delta(delta=delta)\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.register_delta_callback","title":"<code>register_delta_callback(delta_class, fn)</code>","text":"<p>Register a callback that may be triggered when we (eventually) apply an in-order Delta.</p> <p>RTUClient has a separate mechanism for registering delta callbacks from the vanilla Sending .register_callback flow because we don't necessarily want to run callbacks immediately when we observe a Delta come over the RTU websocket. We may be dealing with out-of-order deltas that are queued up and applied later on.</p> <p>These callbacks are triggered by .apply_delta() and stored in a separate callback list from vanilla Sending callbacks (manager.register_callback's)</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>def register_delta_callback(self, delta_class: Type[FileDelta], fn: Callable):\n    \"\"\"\n    Register a callback that may be triggered when we (eventually) apply an in-order Delta.\n\n    RTUClient has a separate mechanism for registering delta callbacks from the vanilla\n    Sending .register_callback flow because we don't necessarily want to run callbacks\n    immediately when we observe a Delta come over the RTU websocket. We may be dealing\n    with out-of-order deltas that are queued up and applied later on.\n\n    These callbacks are triggered by .apply_delta() and stored in a separate callback\n    list from vanilla Sending callbacks (manager.register_callback's)\n    \"\"\"\n    cb = DeltaCallback(delta_class=delta_class, fn=fn)\n    self.delta_callbacks.append(cb)\n    return cb\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.register_rtu_event_callback","title":"<code>register_rtu_event_callback(rtu_event, fn)</code>","text":"<p>Register a callback that will be awaited whenever an RTU event is received that matches the other arguments passed in (event, channel, channel_prefix, transaction_id).</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>def register_rtu_event_callback(self, rtu_event: Type[RTUResponse], fn: Callable) -&gt; Callable:\n    \"\"\"\n    Register a callback that will be awaited whenever an RTU event is received that matches the\n    other arguments passed in (event, channel, channel_prefix, transaction_id).\n    \"\"\"\n\n    # When Sending/RTUManager receives and deserializes a message to an RTU event, it checks\n    # every registered callback. If those have a \"predicate_fn\", it runs that fn against the\n    # incoming message to decide whether to await the callback.\n    # The \"topic\" in the predicate_fn is always hardcoded to \"\" in the websocket backend, it's\n    # used in other backends like redis just not applicable here.\n    def predicate_fn(topic: Literal[\"\"], msg: RTUResponse):\n        return isinstance(msg, rtu_event)\n\n    return self.manager.register_callback(fn, on_predicate=predicate_fn)\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.register_transaction_id_callback","title":"<code>register_transaction_id_callback(transaction_id, fn)</code>","text":"<p>Register a callback that will be triggered whenever an RTU message comes in with a given transaction id. Useful for doing things like waiting for a reply / event or error to be propogated, e.g. for new delta requests.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>def register_transaction_id_callback(self, transaction_id: uuid.UUID, fn: Callable):\n    \"\"\"\n    Register a callback that will be triggered whenever an RTU message comes in with a given\n    transaction id. Useful for doing things like waiting for a reply / event or error to be\n    propogated, e.g. for new delta requests.\n    \"\"\"\n\n    def predicate_fn(topic: Literal[\"\"], msg: RTUResponse):\n        return msg.transaction_id == transaction_id\n\n    return self.manager.register_callback(fn, on_predicate=predicate_fn)\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.replace_cell_content","title":"<code>replace_cell_content(cell_id, source)</code>  <code>async</code>","text":"<p>Replace cell content with a string</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def replace_cell_content(self, cell_id: str, source: str) -&gt; NotebookCell:\n    \"\"\"\n    Replace cell content with a string\n    \"\"\"\n    delta = CellContentsReplace(\n        file_id=self.file_id, resource_id=cell_id, properties={\"source\": source}\n    )\n    await self.new_delta_request(delta)\n    # Grab updated cell post-squashing\n    _, cell = self.builder.get_cell(cell_id)\n    return cell\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.replay_unapplied_deltas","title":"<code>replay_unapplied_deltas()</code>  <code>async</code>","text":"<p>Attempt to apply any previous unapplied Deltas that were received out of order. Calls itself recursively in case replaying unapplied deltas resulted in multiple Deltas now being able to be applied. E.g. we received in order:  - {'id': 2, 'parent_id': 1} # applied because NBBuilder had no last_applied_delta_id  - {'id': 5, 'parent_id': 4} # queued because parent_id doesn't match builder  - {'id': 4, 'parent_id': 3} # queued because parent_id doesn't match builder  - {'id': 3, 'parent_id': 2} # applied, then needs to replay queued deltas</p> <p>Replaying would make the third received delta be applied, which would let replaying again also apply the second delta.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def replay_unapplied_deltas(self):\n    \"\"\"\n    Attempt to apply any previous unapplied Deltas that were received out of order.\n    Calls itself recursively in case replaying unapplied deltas resulted in multiple\n    Deltas now being able to be applied. E.g. we received in order:\n     - {'id': 2, 'parent_id': 1} # applied because NBBuilder had no last_applied_delta_id\n     - {'id': 5, 'parent_id': 4} # queued because parent_id doesn't match builder\n     - {'id': 4, 'parent_id': 3} # queued because parent_id doesn't match builder\n     - {'id': 3, 'parent_id': 2} # applied, then needs to replay queued deltas\n\n    Replaying would make the third received delta be applied, which would let\n    replaying again also apply the second delta.\n    \"\"\"\n    for delta in self.unapplied_deltas:\n        if delta.parent_delta_id == self.builder.last_applied_delta_id:\n            logger.debug(\n                \"Applying previously queued out of order delta\",\n                extra={\"delta_id\": str(delta.id)},\n            )\n            await self.apply_delta(delta=delta)\n            self.unapplied_deltas.remove(delta)\n            return await self.replay_unapplied_deltas()\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.send","title":"<code>send(msg)</code>","text":"<p>Send an RTU message to Noteable. This is not async because what's happening behind the scenes is that RTUManager.send drops the RTU pydantic model onto an \"outbound\" asyncio.Queue then the \"outbound worker\" picks it up off the queue, serializes it to JSON, and sends it out over the wire.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>def send(self, msg: RTURequest):\n    \"\"\"\n    Send an RTU message to Noteable. This is not async because what's happening behind the\n    scenes is that RTUManager.send drops the RTU pydantic model onto an \"outbound\" asyncio.Queue\n    then the \"outbound worker\" picks it up off the queue, serializes it to JSON, and sends it\n    out over the wire.\n    \"\"\"\n    self.manager.send(msg)\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.send_file_subscribe","title":"<code>send_file_subscribe()</code>  <code>async</code>","text":"<p>Once <code>authenticate_reply</code> is observed, we should send the File subscription request.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def send_file_subscribe(self):\n    \"\"\"\n    Once `authenticate_reply` is observed, we should send the File subscription request.\n    \"\"\"\n    # If our NotebookBuilder hasn't applied any deltas yet, then we should subscribe\n    # by the version_id. That is, we think we've pulled down a clean seed Notebook by\n    # s3 version id, and need to get deltas by the matching noteable version id.\n    #\n    # However if we've started applying deltas, such as after a Gate crash and RTU\n    # reconnect, then subscribe by the last applied delta id.\n    #\n    # Note this also means file subscribe won't happen until after we've pulled down\n    # the seed notebook from s3 for the first time, which is probably fine.\n    #\n    # Second note, subscribing by delta id all-0's throws an error in Gate.\n    if self.builder.last_applied_delta_id and self.builder.last_applied_delta_id != uuid.UUID(int=0):  # type: ignore # noqa: E501\n        logger.info(\n            \"Sending File subscribe request by last applied delta id\",\n            extra={\"from_delta_id\": str(self.builder.last_applied_delta_id)},\n        )\n        req_data = FileSubscribeRequestData(from_delta_id=self.builder.last_applied_delta_id)\n        req = FileSubscribeRequest(\n            channel=f\"files/{self.file_id}\",\n            data=req_data,\n        )\n\n    else:\n        logger.info(\n            \"Sending File subscribe request by version id\",\n            extra={\"from_version_id\": str(self.file_version_id)},\n        )\n        req_data = FileSubscribeRequestData(from_version_id=self.file_version_id)\n        req = FileSubscribeRequest(\n            channel=f\"files/{self.file_id}\",\n            data=req_data,\n        )\n\n    self.file_subscribe_timeout_task = asyncio.create_task(self.on_file_subscribe_timeout())\n    self.manager.send(req)\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.update_cell_content","title":"<code>update_cell_content(cell_id, patch)</code>  <code>async</code>","text":"<p>Update cell content with a diff-match-patch patch string</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def update_cell_content(self, cell_id: str, patch: str) -&gt; NotebookCell:\n    \"\"\"\n    Update cell content with a diff-match-patch patch string\n    \"\"\"\n    delta = CellContentsUpdate(\n        file_id=self.file_id, resource_id=cell_id, properties={\"patch\": patch}\n    )\n    await self.new_delta_request(delta)\n    # Grab updated cell post-squashing\n    _, cell = self.builder.get_cell(cell_id)\n    return cell\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUClient.wait_for_kernel_idle","title":"<code>wait_for_kernel_idle()</code>  <code>async</code>","text":"<p>Wait for the kernel to be idle</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def wait_for_kernel_idle(self):\n    \"\"\"Wait for the kernel to be idle\"\"\"\n    logger.debug(\"Waiting for Kernel to be idle\")\n    while self.kernel_state != \"idle\":\n        await asyncio.sleep(0.05)\n    logger.debug(\"Kernel is idle\")\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUManager","title":"<code>RTUManager</code>","text":"<p>             Bases: <code>WebsocketManager</code></p> <ul> <li>Makes a connection to the RTU validation server</li> <li>Handles reconnection if the validation server crashes</li> <li>Serializes inbound messages to rtu.GenericRTUReply and outbound to rtu.GenericRTURequest</li> <li>Adds extra logging kwargs for RTU event type and optional Delta type/action</li> <li>Other classes that use this should add appropriate .auth_hook and .init_hook,   and register callbacks to do something with RTU events (see RTUClient)</li> </ul> Source code in <code>origami/clients/rtu.py</code> <pre><code>class RTUManager(WebsocketManager):\n    \"\"\"\n    - Makes a connection to the RTU validation server\n    - Handles reconnection if the validation server crashes\n    - Serializes inbound messages to rtu.GenericRTUReply and outbound to rtu.GenericRTURequest\n    - Adds extra logging kwargs for RTU event type and optional Delta type/action\n    - Other classes that use this should add appropriate .auth_hook and .init_hook,\n      and register callbacks to do something with RTU events (see RTUClient)\n    \"\"\"\n\n    # Serializing inbound and outbound messages between websocket str payloads and RTU models\n    async def inbound_message_hook(self, contents: str) -&gt; RTUResponse:\n        \"\"\"\n        Hook applied to every message coming in to us over the websocket before the message\n        is passed to registered callback functions.\n\n         - The validation server receives RTU Requests and emits RTU Replies\n         - We're an RTU client, every message we get should parse into an RTU Reply\n         - Registered callback functions should expect to take in an RTU Reply pydantic model\n        \"\"\"\n        # Two-pass parsing, once to BaseRTUResponse to generate channel_prefix dervied value\n        # then a second parse to go through the discriminators to a specific event (or fall back\n        # to error or BaseRTUResponse)\n        data: dict = orjson.loads(contents)\n        data[\"channel_prefix\"] = data.get(\"channel\", \"\").split(\"/\")[0]\n\n        rtu_event = RTUResponseParser.validate_python(data)\n\n        # Debug Logging\n        extra_dict = {\n            \"rtu_event\": rtu_event.event,\n            \"rtu_transaction_id\": str(rtu_event.transaction_id),\n            \"rtu_channel\": rtu_event.channel,\n        }\n        if isinstance(rtu_event, NewDeltaEvent):\n            extra_dict[\"delta_type\"] = rtu_event.data.delta_type\n            extra_dict[\"delta_action\"] = rtu_event.data.delta_action\n\n        if logging.DEBUG &gt;= logging.root.level:\n            logger.debug(f\"Received: {data}\\nParsed: {rtu_event.model_dump()}\", extra=extra_dict)\n\n        return rtu_event\n\n    async def outbound_message_hook(self, contents: RTURequest) -&gt; str:\n        \"\"\"\n        Hook applied to every message we send out over the websocket.\n         - Anything calling .send() should pass in an RTU Request pydantic model\n        \"\"\"\n        return contents.model_dump_json()\n\n    def send(self, message: RTURequest) -&gt; None:\n        \"\"\"Override WebsocketManager-defined method for type hinting and logging.\"\"\"\n        # all this extra stuff is just for logging\n        extra_dict = {\n            \"rtu_event\": message.event,\n            \"rtu_transaction_id\": str(message.transaction_id),\n        }\n        if message.event == \"new_delta_request\":\n            extra_dict[\"delta_type\"] = message.data.delta.delta_type\n            extra_dict[\"delta_action\"] = message.data.delta.delta_action\n\n        logger.debug(\"Sending: RTU request\", extra=extra_dict)\n\n        super().send(message)  # the .outbound_message_hook handles serializing this to json\n\n    async def on_exception(self, exc: Exception):\n        \"\"\"\n        Add a naive delay in reconnecting if we broke the websocket connection because\n        there was a raised Exception in our _poll_loop, e.g. unserializable messages\n        or syntax errors somewhere in our code.\n\n        TODO: Make this elegant, perhaps a backoff strategy in Sending base.py\n        \"\"\"\n        await super().on_exception(exc)\n        # Sleep 1 second per number of reconnections we've made\n        await asyncio.sleep(self.reconnections)\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUManager.inbound_message_hook","title":"<code>inbound_message_hook(contents)</code>  <code>async</code>","text":"<p>Hook applied to every message coming in to us over the websocket before the message is passed to registered callback functions.</p> <ul> <li>The validation server receives RTU Requests and emits RTU Replies</li> <li>We're an RTU client, every message we get should parse into an RTU Reply</li> <li>Registered callback functions should expect to take in an RTU Reply pydantic model</li> </ul> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def inbound_message_hook(self, contents: str) -&gt; RTUResponse:\n    \"\"\"\n    Hook applied to every message coming in to us over the websocket before the message\n    is passed to registered callback functions.\n\n     - The validation server receives RTU Requests and emits RTU Replies\n     - We're an RTU client, every message we get should parse into an RTU Reply\n     - Registered callback functions should expect to take in an RTU Reply pydantic model\n    \"\"\"\n    # Two-pass parsing, once to BaseRTUResponse to generate channel_prefix dervied value\n    # then a second parse to go through the discriminators to a specific event (or fall back\n    # to error or BaseRTUResponse)\n    data: dict = orjson.loads(contents)\n    data[\"channel_prefix\"] = data.get(\"channel\", \"\").split(\"/\")[0]\n\n    rtu_event = RTUResponseParser.validate_python(data)\n\n    # Debug Logging\n    extra_dict = {\n        \"rtu_event\": rtu_event.event,\n        \"rtu_transaction_id\": str(rtu_event.transaction_id),\n        \"rtu_channel\": rtu_event.channel,\n    }\n    if isinstance(rtu_event, NewDeltaEvent):\n        extra_dict[\"delta_type\"] = rtu_event.data.delta_type\n        extra_dict[\"delta_action\"] = rtu_event.data.delta_action\n\n    if logging.DEBUG &gt;= logging.root.level:\n        logger.debug(f\"Received: {data}\\nParsed: {rtu_event.model_dump()}\", extra=extra_dict)\n\n    return rtu_event\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUManager.on_exception","title":"<code>on_exception(exc)</code>  <code>async</code>","text":"<p>Add a naive delay in reconnecting if we broke the websocket connection because there was a raised Exception in our _poll_loop, e.g. unserializable messages or syntax errors somewhere in our code.</p> <p>TODO: Make this elegant, perhaps a backoff strategy in Sending base.py</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def on_exception(self, exc: Exception):\n    \"\"\"\n    Add a naive delay in reconnecting if we broke the websocket connection because\n    there was a raised Exception in our _poll_loop, e.g. unserializable messages\n    or syntax errors somewhere in our code.\n\n    TODO: Make this elegant, perhaps a backoff strategy in Sending base.py\n    \"\"\"\n    await super().on_exception(exc)\n    # Sleep 1 second per number of reconnections we've made\n    await asyncio.sleep(self.reconnections)\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUManager.outbound_message_hook","title":"<code>outbound_message_hook(contents)</code>  <code>async</code>","text":"<p>Hook applied to every message we send out over the websocket.  - Anything calling .send() should pass in an RTU Request pydantic model</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>async def outbound_message_hook(self, contents: RTURequest) -&gt; str:\n    \"\"\"\n    Hook applied to every message we send out over the websocket.\n     - Anything calling .send() should pass in an RTU Request pydantic model\n    \"\"\"\n    return contents.model_dump_json()\n</code></pre>"},{"location":"reference/clients/rtu/#clients.rtu.RTUManager.send","title":"<code>send(message)</code>","text":"<p>Override WebsocketManager-defined method for type hinting and logging.</p> Source code in <code>origami/clients/rtu.py</code> <pre><code>def send(self, message: RTURequest) -&gt; None:\n    \"\"\"Override WebsocketManager-defined method for type hinting and logging.\"\"\"\n    # all this extra stuff is just for logging\n    extra_dict = {\n        \"rtu_event\": message.event,\n        \"rtu_transaction_id\": str(message.transaction_id),\n    }\n    if message.event == \"new_delta_request\":\n        extra_dict[\"delta_type\"] = message.data.delta.delta_type\n        extra_dict[\"delta_action\"] = message.data.delta.delta_action\n\n    logger.debug(\"Sending: RTU request\", extra=extra_dict)\n\n    super().send(message)  # the .outbound_message_hook handles serializing this to json\n</code></pre>"},{"location":"reference/models/kernels/","title":"kernels","text":""},{"location":"reference/models/notebook/","title":"notebook","text":"<p>Modeling the Notebook File Format with Pydantic models. It also includes some helper properties relevant to Noteable format, such as whether a code cell is a SQL cell and retrieving the output collection id, which is a Noteable-specific cell output context.</p> <p>See https://nbformat.readthedocs.io/en/latest/format_description.html# for Notebook model spec.</p> <p>Devs: as usual with Pydantic modeling, the top-level model (Notebook) is at the bottom of this file, read from bottom up for most clarity.</p>"},{"location":"reference/models/notebook/#models.notebook.CellBase","title":"<code>CellBase</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>All Cell types have id, source and metadata. The source can be a string or list of strings in nbformat spec, but we only want to deal with source as a string throughout our code base so we have a validator here to cast the list of strings to a single string, both at initial read and during any mutations (e.g. applying diff-match-patch cell content updates).</p> Source code in <code>origami/models/notebook.py</code> <pre><code>class CellBase(BaseModel):\n    \"\"\"\n    All Cell types have id, source and metadata.\n    The source can be a string or list of strings in nbformat spec,\n    but we only want to deal with source as a string throughout our\n    code base so we have a validator here to cast the list of strings\n    to a single string, both at initial read and during any mutations\n    (e.g. applying diff-match-patch cell content updates).\n    \"\"\"\n\n    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    source: str = \"\"\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n\n    @field_validator(\"source\", mode=\"before\")\n    @classmethod\n    def multiline_source(cls, v):\n        if isinstance(v, list):\n            return \"\\n\".join(v)\n        return v\n\n    model_config = ConfigDict(validate_on_assignment=True)\n</code></pre>"},{"location":"reference/models/notebook/#models.notebook.StreamOutput","title":"<code>StreamOutput</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>origami/models/notebook.py</code> <pre><code>class StreamOutput(BaseModel):\n    output_type: Literal[\"stream\"] = \"stream\"\n    name: str  # stdout or stderr\n    text: str\n\n    @field_validator(\"text\", mode=\"before\")\n    @classmethod\n    def multiline_text(cls, v):\n        \"\"\"In the event we get a list of strings, combine into one string with newlines.\"\"\"\n        if isinstance(v, list):\n            return \"\\n\".join(v)\n        return v\n</code></pre>"},{"location":"reference/models/notebook/#models.notebook.StreamOutput.multiline_text","title":"<code>multiline_text(v)</code>  <code>classmethod</code>","text":"<p>In the event we get a list of strings, combine into one string with newlines.</p> Source code in <code>origami/models/notebook.py</code> <pre><code>@field_validator(\"text\", mode=\"before\")\n@classmethod\ndef multiline_text(cls, v):\n    \"\"\"In the event we get a list of strings, combine into one string with newlines.\"\"\"\n    if isinstance(v, list):\n        return \"\\n\".join(v)\n    return v\n</code></pre>"},{"location":"reference/models/api/base/","title":"base","text":""},{"location":"reference/models/api/datasources/","title":"datasources","text":""},{"location":"reference/models/api/files/","title":"files","text":""},{"location":"reference/models/api/outputs/","title":"outputs","text":""},{"location":"reference/models/api/projects/","title":"projects","text":""},{"location":"reference/models/api/spaces/","title":"spaces","text":""},{"location":"reference/models/api/users/","title":"users","text":""},{"location":"reference/models/api/users/#models.api.users.User","title":"<code>User</code>","text":"<p>             Bases: <code>ResourceBase</code></p> <p>The user fields sent to/from the server</p> Source code in <code>origami/models/api/users.py</code> <pre><code>class User(ResourceBase):\n    \"\"\"The user fields sent to/from the server\"\"\"\n\n    handle: str\n    email: Optional[str] = None  # not returned if looking up user other than yourself\n    first_name: str\n    last_name: str\n    origamist_default_project_id: Optional[uuid.UUID] = None\n    principal_sub: Optional[str] = None  # from /users/me only, represents auth type\n    auth_type: Optional[str] = None\n\n    @model_validator(mode=\"after\")\n    def construct_auth_type(self):\n        if self.principal_sub:\n            self.auth_type = self.principal_sub.split(\"|\")[0]\n\n        return self\n</code></pre>"},{"location":"reference/models/deltas/base/","title":"base","text":""},{"location":"reference/models/deltas/discriminators/","title":"discriminators","text":""},{"location":"reference/models/deltas/delta_types/cell_contents/","title":"cell_contents","text":""},{"location":"reference/models/deltas/delta_types/cell_execute/","title":"cell_execute","text":""},{"location":"reference/models/deltas/delta_types/cell_metadata/","title":"cell_metadata","text":""},{"location":"reference/models/deltas/delta_types/cell_output_collection/","title":"cell_output_collection","text":""},{"location":"reference/models/deltas/delta_types/nb_cells/","title":"nb_cells","text":""},{"location":"reference/models/deltas/delta_types/nb_metadata/","title":"nb_metadata","text":""},{"location":"reference/models/rtu/base/","title":"base","text":""},{"location":"reference/models/rtu/discriminators/","title":"discriminators","text":""},{"location":"reference/models/rtu/errors/","title":"errors","text":""},{"location":"reference/models/rtu/channels/files/","title":"files","text":"<p>There are six events on the files/ channel: <ol> <li>subscribe_request and subscribe_reply</li> <li>unsubscribe_request and unsubscribe_reply</li> <li>new_delta_request and new_delta_reply (direct) / new_delta_event (broadcast)</li> <li>RTU Errors for invalid_data or permission_denied</li> <li>update_user_cell_selection_request and    update_user_cell_selection_reply -&gt; update_user_file_subscription_event</li> <li>input_reply_request and input_reply_reply</li> <li>transform_view_to_code_request and transform_view_to_code_reply (DEX export to code cell)</li> <li>The follow on \"event\" is a new delta event</li> </ol>"},{"location":"reference/models/rtu/channels/kernels/","title":"kernels","text":"<p>The kernels channel in RTU is primarily used for runtime updates like kernel and cell status, variable explorer, and outputs vice document model changes on the files channel (adding cells, updating content, etc)</p>"},{"location":"reference/models/rtu/channels/system/","title":"system","text":"<p>The primary purpose of the system channel is authenticating an RTU session after the websocket connection has been established. There are a number of debug-related RTU events on this channel as well.</p> <ol> <li>authenticate_request - pass in a JWT to authenticate the rest of the RTU session so that events    on channels like files and projects, which require RBAC checks, have a User account to check</li> <li>ping_request and ping_reply - used to test RTU connection</li> <li>whoami_request and whoami_reply - used to get the User account associated with the RTU session    (also returned as part of the payload on the authenticate_reply event though)</li> </ol>"},{"location":"reference/notebook/builder/","title":"builder","text":"<p>The NotebookBuilder is used in applications that need to keep an in-memory representation of a Notebook and update it with RTU / Delta formatted messages.</p>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder","title":"<code>NotebookBuilder</code>","text":"<p>Apply RTU File Deltas to an in-memory representation of a Notebook.</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>class NotebookBuilder:\n    \"\"\"\n    Apply RTU File Deltas to an in-memory representation of a Notebook.\n    \"\"\"\n\n    def __init__(self, seed_notebook: Notebook):\n        if not isinstance(seed_notebook, Notebook):\n            raise TypeError(\"seed_notebook must be a Pydantic Notebook model\")\n        self._seed_notebook = seed_notebook\n        self.nb: Notebook = seed_notebook.model_copy()\n        self.dmp = diff_match_patch.diff_match_patch()\n\n        cell_id_counts = collections.defaultdict(int)\n        for cell in self.nb.cells:\n            cell_id_counts[cell.id] += 1\n        for cell_id, count in cell_id_counts.items():\n            if count &gt; 1:\n                logger.warning(f\"Found {count} cells with id {cell_id}\")\n\n        # RTUClient uses the builder.last_applied_delta_id to figure out whether to apply incoming\n        # deltas or queue them in an unapplied_deltas list for replay\n        self.last_applied_delta_id: Optional[uuid.UUID] = None\n        # to keep track of deleted cells so we can ignore them in future deltas\n        self.deleted_cell_ids: set[str] = set()\n\n    @property\n    def cell_ids(self) -&gt; list[str]:\n        return [cell.id for cell in self.nb.cells]\n\n    @classmethod\n    def from_nbformat(self, nb: nbformat.NotebookNode) -&gt; \"NotebookBuilder\":\n        \"\"\"Instantiate a NotebookBuilder from a nbformat NotebookNode\"\"\"\n        nb = Notebook.parse_obj(nb.dict())\n        return NotebookBuilder(nb)\n\n    def get_cell(self, cell_id: str) -&gt; Tuple[int, NotebookCell]:\n        \"\"\"\n        Convenience method to return a cell by cell id.\n        Raises CellNotFound if cell id is not in the Notebook\n        \"\"\"\n        for index, cell in enumerate(self.nb.cells):\n            if cell.id == cell_id:\n                return (index, cell)\n        raise CellNotFound(cell_id)\n\n    def apply_delta(self, delta: FileDelta) -&gt; None:\n        \"\"\"\n        Apply a FileDelta to the NotebookBuilder.\n        \"\"\"\n        handlers: Dict[Type[FileDelta], Callable] = {\n            NBCellsAdd: self.add_cell,\n            NBCellsDelete: self.delete_cell,\n            NBCellsMove: self.move_cell,\n            CellContentsUpdate: self.update_cell_contents,\n            CellContentsReplace: self.replace_cell_contents,\n            CellMetadataUpdate: self.update_cell_metadata,\n            CellMetadataReplace: self.replace_cell_metadata,\n            NBMetadataUpdate: self.update_notebook_metadata,\n            CellOutputCollectionReplace: self.replace_cell_output_collection,\n            CellExecute: self.log_execute_delta,\n            CellExecuteAll: self.log_execute_delta,\n            CellExecuteBefore: self.log_execute_delta,\n            CellExecuteAfter: self.log_execute_delta,\n        }\n        if type(delta) not in handlers:\n            raise ValueError(f\"No handler for {delta.delta_type=}, {delta.delta_action=}\")\n\n        handler = handlers[type(delta)]\n        try:\n            handler(delta)\n            self.last_applied_delta_id = delta.id\n        except Exception as e:  # noqa: E722\n            logger.exception(\"Error squashing Delta into NotebookBuilder\", extra={\"delta\": delta})\n            raise e\n\n    def add_cell(self, delta: NBCellsAdd):\n        \"\"\"\n        Add a new cell to the Notebook.\n         - If after_id is specified, add it after that cell. Otherwise at top of Notebook\n         - cell_id can be specified at higher level delta.properties and should be copied down into\n           the cell part of the delta.properties\n        \"\"\"\n        cell_id = delta.properties.id\n        # Warning if we're adding a duplicate cell id\n        if cell_id in self.cell_ids:\n            logger.warning(\n                f\"Received NBCellsAdd delta with cell id {cell_id}, duplicate of existing cell\"\n            )\n        new_cell = delta.properties.cell\n        # Push \"delta.properites.id\" down into cell id ...\n        new_cell.id = cell_id\n        if delta.properties.after_id:\n            index, _ = self.get_cell(delta.properties.after_id)\n            self.nb.cells.insert(index + 1, new_cell)\n        else:\n            self.nb.cells.insert(0, new_cell)\n\n    def delete_cell(self, delta: NBCellsDelete):\n        \"\"\"Deletes a cell from the Notebook. If the cell can't be found, warn but don't error.\"\"\"\n        cell_id = delta.properties.id\n        index, _ = self.get_cell(cell_id)\n        self.nb.cells.pop(index)\n        self.deleted_cell_ids.add(cell_id)\n\n    def move_cell(self, delta: NBCellsMove):\n        \"\"\"Moves a cell from one position to another in the Notebook\"\"\"\n        cell_id = delta.properties.id\n        index, _ = self.get_cell(cell_id)\n        cell_to_move = self.nb.cells.pop(index)\n        if delta.properties.after_id:\n            target_index, _ = self.get_cell(delta.properties.after_id)\n            self.nb.cells.insert(target_index + 1, cell_to_move)\n            return\n        else:\n            self.nb.cells.insert(0, cell_to_move)\n\n    def update_cell_contents(self, delta: CellContentsUpdate):\n        \"\"\"Update cell content using the diff-match-patch algorithm\"\"\"\n        patches = self.dmp.patch_fromText(delta.properties.patch)\n        _, cell = self.get_cell(delta.resource_id)\n        merged_text = self.dmp.patch_apply(patches, cell.source)[0]\n        cell.source = merged_text\n\n    def replace_cell_contents(self, delta: CellContentsReplace):\n        \"\"\"Pure replacement of cell source content\"\"\"\n        _, cell = self.get_cell(delta.resource_id)\n        cell.source = delta.properties.source\n\n    def update_notebook_metadata(self, delta: NBMetadataUpdate):\n        \"\"\"Update top-level Notebook metadata using a partial update / nested path technique\"\"\"\n        # Need to traverse the Notebook metadata dictionary by a list of keys.\n        # If that key isn't there already, create it with value of empty dict\n        # e.g. path=['foo', 'bar', 'baz'], value='xyz' needs to set\n        # self.nb.metadata['foo']['bar']['baz'] = 'xyz'\n        # and add those nested keys into metadata if they don't exist already\n        dict_path = self.nb.metadata\n        for leading_key in delta.properties.path[:-1]:\n            if leading_key not in dict_path:\n                dict_path[leading_key] = {}\n            dict_path = dict_path[leading_key]\n\n        last_key = delta.properties.path[-1]\n        if (\n            last_key in dict_path\n            and delta.properties.prior_value\n            and delta.properties.prior_value != NULL_PRIOR_VALUE_SENTINEL\n            and dict_path[last_key] != delta.properties.prior_value\n        ):\n            logger.warning(\n                f\"Notebook metadata path {delta.properties.path} expected to have prior value {delta.properties.prior_value} but was {dict_path[last_key]}\"  # noqa: E501\n            )\n\n        dict_path[last_key] = delta.properties.value\n\n    def update_cell_metadata(self, delta: CellMetadataUpdate):\n        \"\"\"Update cell metadata using a partial update / nested path technique\"\"\"\n        if delta.resource_id in self.deleted_cell_ids:\n            logger.debug(\n                f\"Skipping update_cell_metadata for deleted cell {delta.resource_id}\",\n                extra={\"delta_properties_path\": delta.properties.path},\n            )\n            return\n\n        try:\n            _, cell = self.get_cell(delta.resource_id)\n        except CellNotFound:\n            # Most often happens when a User deletes a cell that's in progress of being executed,\n            # and we end up emitting a cell execution timing metadata as it gets deleted\n            logger.warning(\n                \"Got update_cell_metadata for cell that isn't in notebook or deleted_cell_ids\",  # noqa: E501\n                extra={\"delta_properties_path\": delta.properties.path},\n            )\n            return\n\n        # see comment in update_notebook_metadata explaining dictionary traversal\n        dict_path = cell.metadata\n        for leading_key in delta.properties.path[:-1]:\n            if leading_key not in dict_path:\n                dict_path[leading_key] = {}\n            dict_path = dict_path[leading_key]\n\n        last_key = delta.properties.path[-1]\n        if (\n            last_key in dict_path\n            and delta.properties.prior_value\n            and delta.properties.prior_value != NULL_PRIOR_VALUE_SENTINEL\n            and str(dict_path[last_key]) != str(delta.properties.prior_value)\n        ):\n            logger.warning(\n                f\"Cell {cell.id} metadata path {delta.properties.path} expected to have prior value {delta.properties.prior_value} but was {dict_path[last_key]}\"  # noqa: E501\n            )\n\n        dict_path[last_key] = delta.properties.value\n\n    def replace_cell_metadata(self, delta: CellMetadataReplace):\n        \"\"\"Switch a cell type between code / markdown or change cell language (e.g. Python to R)\"\"\"\n        _, cell = self.get_cell(delta.resource_id)\n\n        if delta.properties.type:\n            cell.cell_type = delta.properties.type\n        if delta.properties.language:\n            if \"noteable\" not in cell.metadata:\n                cell.metadata[\"noteable\"] = {}\n            cell.metadata[\"noteable\"][\"cell_type\"] = delta.properties.language\n\n    def replace_cell_output_collection(self, delta: CellOutputCollectionReplace):\n        \"\"\"Update cell metadata to point to an Output Collection container id\"\"\"\n        if delta.resource_id in self.deleted_cell_ids:\n            logger.warning(\n                f\"Skipping replace_cell_output_collection for deleted cell {delta.resource_id}\"\n            )\n            return\n\n        try:\n            _, cell = self.get_cell(delta.resource_id)\n        except CellNotFound:\n            logger.warning(\n                \"Got replace_cell_output_collection for cell that isn't in notebook or deleted_cell_ids\",  # noqa: E501\n            )\n            return\n\n        if \"noteable\" not in cell.metadata:\n            cell.metadata[\"noteable\"] = {}\n        cell.metadata[\"noteable\"][\"output_collection_id\"] = delta.properties.output_collection_id\n\n    def log_execute_delta(\n        self, delta: Union[CellExecute, CellExecuteBefore, CellExecuteAfter, CellExecuteAll]\n    ):\n        \"\"\"Handles delta_type: execute, delta_action: execute | execute_all\"\"\"\n        logger.debug(\n            \"Squashing execute delta\",\n            extra={\"delta_type\": delta.delta_type, \"delta_action\": delta.delta_action},\n        )\n        pass\n\n    def dumps(self, indent: bool = True) -&gt; bytes:\n        \"\"\"\n        Serialize the in-memory Notebook to JSON.\n        \"\"\"\n        if indent:\n            return orjson.dumps(self.nb.dict(exclude_unset=True), option=orjson.OPT_INDENT_2)\n        else:\n            return orjson.dumps(self.nb.dict(exclude_unset=True))\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.add_cell","title":"<code>add_cell(delta)</code>","text":"<p>Add a new cell to the Notebook.  - If after_id is specified, add it after that cell. Otherwise at top of Notebook  - cell_id can be specified at higher level delta.properties and should be copied down into    the cell part of the delta.properties</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def add_cell(self, delta: NBCellsAdd):\n    \"\"\"\n    Add a new cell to the Notebook.\n     - If after_id is specified, add it after that cell. Otherwise at top of Notebook\n     - cell_id can be specified at higher level delta.properties and should be copied down into\n       the cell part of the delta.properties\n    \"\"\"\n    cell_id = delta.properties.id\n    # Warning if we're adding a duplicate cell id\n    if cell_id in self.cell_ids:\n        logger.warning(\n            f\"Received NBCellsAdd delta with cell id {cell_id}, duplicate of existing cell\"\n        )\n    new_cell = delta.properties.cell\n    # Push \"delta.properites.id\" down into cell id ...\n    new_cell.id = cell_id\n    if delta.properties.after_id:\n        index, _ = self.get_cell(delta.properties.after_id)\n        self.nb.cells.insert(index + 1, new_cell)\n    else:\n        self.nb.cells.insert(0, new_cell)\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.apply_delta","title":"<code>apply_delta(delta)</code>","text":"<p>Apply a FileDelta to the NotebookBuilder.</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def apply_delta(self, delta: FileDelta) -&gt; None:\n    \"\"\"\n    Apply a FileDelta to the NotebookBuilder.\n    \"\"\"\n    handlers: Dict[Type[FileDelta], Callable] = {\n        NBCellsAdd: self.add_cell,\n        NBCellsDelete: self.delete_cell,\n        NBCellsMove: self.move_cell,\n        CellContentsUpdate: self.update_cell_contents,\n        CellContentsReplace: self.replace_cell_contents,\n        CellMetadataUpdate: self.update_cell_metadata,\n        CellMetadataReplace: self.replace_cell_metadata,\n        NBMetadataUpdate: self.update_notebook_metadata,\n        CellOutputCollectionReplace: self.replace_cell_output_collection,\n        CellExecute: self.log_execute_delta,\n        CellExecuteAll: self.log_execute_delta,\n        CellExecuteBefore: self.log_execute_delta,\n        CellExecuteAfter: self.log_execute_delta,\n    }\n    if type(delta) not in handlers:\n        raise ValueError(f\"No handler for {delta.delta_type=}, {delta.delta_action=}\")\n\n    handler = handlers[type(delta)]\n    try:\n        handler(delta)\n        self.last_applied_delta_id = delta.id\n    except Exception as e:  # noqa: E722\n        logger.exception(\"Error squashing Delta into NotebookBuilder\", extra={\"delta\": delta})\n        raise e\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.delete_cell","title":"<code>delete_cell(delta)</code>","text":"<p>Deletes a cell from the Notebook. If the cell can't be found, warn but don't error.</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def delete_cell(self, delta: NBCellsDelete):\n    \"\"\"Deletes a cell from the Notebook. If the cell can't be found, warn but don't error.\"\"\"\n    cell_id = delta.properties.id\n    index, _ = self.get_cell(cell_id)\n    self.nb.cells.pop(index)\n    self.deleted_cell_ids.add(cell_id)\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.dumps","title":"<code>dumps(indent=True)</code>","text":"<p>Serialize the in-memory Notebook to JSON.</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def dumps(self, indent: bool = True) -&gt; bytes:\n    \"\"\"\n    Serialize the in-memory Notebook to JSON.\n    \"\"\"\n    if indent:\n        return orjson.dumps(self.nb.dict(exclude_unset=True), option=orjson.OPT_INDENT_2)\n    else:\n        return orjson.dumps(self.nb.dict(exclude_unset=True))\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.from_nbformat","title":"<code>from_nbformat(nb)</code>  <code>classmethod</code>","text":"<p>Instantiate a NotebookBuilder from a nbformat NotebookNode</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>@classmethod\ndef from_nbformat(self, nb: nbformat.NotebookNode) -&gt; \"NotebookBuilder\":\n    \"\"\"Instantiate a NotebookBuilder from a nbformat NotebookNode\"\"\"\n    nb = Notebook.parse_obj(nb.dict())\n    return NotebookBuilder(nb)\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.get_cell","title":"<code>get_cell(cell_id)</code>","text":"<p>Convenience method to return a cell by cell id. Raises CellNotFound if cell id is not in the Notebook</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def get_cell(self, cell_id: str) -&gt; Tuple[int, NotebookCell]:\n    \"\"\"\n    Convenience method to return a cell by cell id.\n    Raises CellNotFound if cell id is not in the Notebook\n    \"\"\"\n    for index, cell in enumerate(self.nb.cells):\n        if cell.id == cell_id:\n            return (index, cell)\n    raise CellNotFound(cell_id)\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.log_execute_delta","title":"<code>log_execute_delta(delta)</code>","text":"<p>Handles delta_type: execute, delta_action: execute | execute_all</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def log_execute_delta(\n    self, delta: Union[CellExecute, CellExecuteBefore, CellExecuteAfter, CellExecuteAll]\n):\n    \"\"\"Handles delta_type: execute, delta_action: execute | execute_all\"\"\"\n    logger.debug(\n        \"Squashing execute delta\",\n        extra={\"delta_type\": delta.delta_type, \"delta_action\": delta.delta_action},\n    )\n    pass\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.move_cell","title":"<code>move_cell(delta)</code>","text":"<p>Moves a cell from one position to another in the Notebook</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def move_cell(self, delta: NBCellsMove):\n    \"\"\"Moves a cell from one position to another in the Notebook\"\"\"\n    cell_id = delta.properties.id\n    index, _ = self.get_cell(cell_id)\n    cell_to_move = self.nb.cells.pop(index)\n    if delta.properties.after_id:\n        target_index, _ = self.get_cell(delta.properties.after_id)\n        self.nb.cells.insert(target_index + 1, cell_to_move)\n        return\n    else:\n        self.nb.cells.insert(0, cell_to_move)\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.replace_cell_contents","title":"<code>replace_cell_contents(delta)</code>","text":"<p>Pure replacement of cell source content</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def replace_cell_contents(self, delta: CellContentsReplace):\n    \"\"\"Pure replacement of cell source content\"\"\"\n    _, cell = self.get_cell(delta.resource_id)\n    cell.source = delta.properties.source\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.replace_cell_metadata","title":"<code>replace_cell_metadata(delta)</code>","text":"<p>Switch a cell type between code / markdown or change cell language (e.g. Python to R)</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def replace_cell_metadata(self, delta: CellMetadataReplace):\n    \"\"\"Switch a cell type between code / markdown or change cell language (e.g. Python to R)\"\"\"\n    _, cell = self.get_cell(delta.resource_id)\n\n    if delta.properties.type:\n        cell.cell_type = delta.properties.type\n    if delta.properties.language:\n        if \"noteable\" not in cell.metadata:\n            cell.metadata[\"noteable\"] = {}\n        cell.metadata[\"noteable\"][\"cell_type\"] = delta.properties.language\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.replace_cell_output_collection","title":"<code>replace_cell_output_collection(delta)</code>","text":"<p>Update cell metadata to point to an Output Collection container id</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def replace_cell_output_collection(self, delta: CellOutputCollectionReplace):\n    \"\"\"Update cell metadata to point to an Output Collection container id\"\"\"\n    if delta.resource_id in self.deleted_cell_ids:\n        logger.warning(\n            f\"Skipping replace_cell_output_collection for deleted cell {delta.resource_id}\"\n        )\n        return\n\n    try:\n        _, cell = self.get_cell(delta.resource_id)\n    except CellNotFound:\n        logger.warning(\n            \"Got replace_cell_output_collection for cell that isn't in notebook or deleted_cell_ids\",  # noqa: E501\n        )\n        return\n\n    if \"noteable\" not in cell.metadata:\n        cell.metadata[\"noteable\"] = {}\n    cell.metadata[\"noteable\"][\"output_collection_id\"] = delta.properties.output_collection_id\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.update_cell_contents","title":"<code>update_cell_contents(delta)</code>","text":"<p>Update cell content using the diff-match-patch algorithm</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def update_cell_contents(self, delta: CellContentsUpdate):\n    \"\"\"Update cell content using the diff-match-patch algorithm\"\"\"\n    patches = self.dmp.patch_fromText(delta.properties.patch)\n    _, cell = self.get_cell(delta.resource_id)\n    merged_text = self.dmp.patch_apply(patches, cell.source)[0]\n    cell.source = merged_text\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.update_cell_metadata","title":"<code>update_cell_metadata(delta)</code>","text":"<p>Update cell metadata using a partial update / nested path technique</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def update_cell_metadata(self, delta: CellMetadataUpdate):\n    \"\"\"Update cell metadata using a partial update / nested path technique\"\"\"\n    if delta.resource_id in self.deleted_cell_ids:\n        logger.debug(\n            f\"Skipping update_cell_metadata for deleted cell {delta.resource_id}\",\n            extra={\"delta_properties_path\": delta.properties.path},\n        )\n        return\n\n    try:\n        _, cell = self.get_cell(delta.resource_id)\n    except CellNotFound:\n        # Most often happens when a User deletes a cell that's in progress of being executed,\n        # and we end up emitting a cell execution timing metadata as it gets deleted\n        logger.warning(\n            \"Got update_cell_metadata for cell that isn't in notebook or deleted_cell_ids\",  # noqa: E501\n            extra={\"delta_properties_path\": delta.properties.path},\n        )\n        return\n\n    # see comment in update_notebook_metadata explaining dictionary traversal\n    dict_path = cell.metadata\n    for leading_key in delta.properties.path[:-1]:\n        if leading_key not in dict_path:\n            dict_path[leading_key] = {}\n        dict_path = dict_path[leading_key]\n\n    last_key = delta.properties.path[-1]\n    if (\n        last_key in dict_path\n        and delta.properties.prior_value\n        and delta.properties.prior_value != NULL_PRIOR_VALUE_SENTINEL\n        and str(dict_path[last_key]) != str(delta.properties.prior_value)\n    ):\n        logger.warning(\n            f\"Cell {cell.id} metadata path {delta.properties.path} expected to have prior value {delta.properties.prior_value} but was {dict_path[last_key]}\"  # noqa: E501\n        )\n\n    dict_path[last_key] = delta.properties.value\n</code></pre>"},{"location":"reference/notebook/builder/#notebook.builder.NotebookBuilder.update_notebook_metadata","title":"<code>update_notebook_metadata(delta)</code>","text":"<p>Update top-level Notebook metadata using a partial update / nested path technique</p> Source code in <code>origami/notebook/builder.py</code> <pre><code>def update_notebook_metadata(self, delta: NBMetadataUpdate):\n    \"\"\"Update top-level Notebook metadata using a partial update / nested path technique\"\"\"\n    # Need to traverse the Notebook metadata dictionary by a list of keys.\n    # If that key isn't there already, create it with value of empty dict\n    # e.g. path=['foo', 'bar', 'baz'], value='xyz' needs to set\n    # self.nb.metadata['foo']['bar']['baz'] = 'xyz'\n    # and add those nested keys into metadata if they don't exist already\n    dict_path = self.nb.metadata\n    for leading_key in delta.properties.path[:-1]:\n        if leading_key not in dict_path:\n            dict_path[leading_key] = {}\n        dict_path = dict_path[leading_key]\n\n    last_key = delta.properties.path[-1]\n    if (\n        last_key in dict_path\n        and delta.properties.prior_value\n        and delta.properties.prior_value != NULL_PRIOR_VALUE_SENTINEL\n        and dict_path[last_key] != delta.properties.prior_value\n    ):\n        logger.warning(\n            f\"Notebook metadata path {delta.properties.path} expected to have prior value {delta.properties.prior_value} but was {dict_path[last_key]}\"  # noqa: E501\n        )\n\n    dict_path[last_key] = delta.properties.value\n</code></pre>"}]}